{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce40dd99",
   "metadata": {
    "id": "ce40dd99"
   },
   "source": [
    "### This Jupyter Notebook presents a methodological template for conducting both Exploratory Data Analysis (EDA) and Predictive Modeling. The techniques are illustrated using an example dataset and are structured for straightforward adaptation to alternative datasets.\n",
    "\n",
    "The aim of this jupyter book is to demonstrate some of the python tools to perform exploratory data analysis and predictive modeling.\n",
    "EDA is the phase of analysis aimed at understanding the characteristics of the data and uncovering patterns. It typically precedes predictive modeling. Model building allows us to make predictions and derive insights from data.\n",
    "\n",
    "### Steps that the code performs:\n",
    "\n",
    "1. **Data Loading and Cleaning:** The code loads data from an Excel file, cleans the column names, and handles missing values. It also removes duplicate rows and columns, as well as those with a unique value.\n",
    "2. **Feature Creation and Type Changing:** The code creates a new feature called Qv_MJ_l and converts the data types of some columns to numeric if they aren't already. It transforms a categorical variable into a numerical one and selects the numeric columns for further analysis.\n",
    "3. **Data Analysis and Visualization:** The code calculates basic statistics and standardised values for the numeric columns. It looks for outliers using three standard deviations and the interquartile range (IQR). It computes the correlation matrix between variables and visualises it using a heatmap. It generates distribution plots and box plots for key parameters. It analyses trends and relationships between variables using scatter plots and pair plots.\n",
    "4. **Summary of Findings:** The code generates a summary table of key metrics and saves the processed data to a new Excel file.\n",
    "5. **Data Processing:** The code performs a classical linear regression with statsmodels. It selects features and the target variable, adds a constant term for the intercept, and fits the model. It draws a y-ypredict scatterplot and checks the variance inflation factor (VIF). It removes some features and fits a new model. It creates regression plots and checks the VIF.\n",
    "6. **Stepwise Regression Technique:** The code utilises a function to add and select features by steps according to AIC/BIC criteria. It fits the model to the selected features and draws a y-ypredict scatterplot and checks the VIF.\n",
    "7. **Linear Regression using scikit_learn and Cross-Validation (cv):** The code loads additional libraries and instantiates LinearRegression. It defines initial parameters and splits data into training and testing sets. It uses RFECV for recursive feature elimination with cross-validation. It checks the results to select features.\n",
    "8. **Comparing Results:** The code defines a function to calculate rmse from cv_test (train) and test: Linear Regression. It calculates the results of linear regression, lasso regression and ridge regression.\n",
    "9. **Principal Component Regression (PCR) and Cross-Validation:** The code attempts PCA analysis for regression of principal components. It calculates principal components and displays feature weights of each principal component. It checks the most important features for each principal component. It calculates RMSE using KFold and looks for the best option. It selects the number of principal components and calculates train and test rmse. It calculates R2 score and draws the residuals scatterplot.\n",
    "10. **Partial Least Squares (PLS) regression:** The code utilises PLS regression with cross-validation. It looks for the best number of components and displays results. It checks R2 score for the best estimator. It utilises a function for sequential feature/component elimination. It displays the result with the best score and checks other good solutions.\n",
    "11. **Random Forest Regression:** The code utilises Random Forest Regression with cross-validation. It looks for the best hyperparameters using GridSearchCV. It evaluates the model using RMSE and R2. It plots feature importances. It displays the scatterplot of the prediction. It calculates the OOB (Out-of-Bag) score.\n",
    "12. **Shap (SHapley Additive exPlanations):**  The code utilises SHAP to explain the output of Random Forest Regression model.\n",
    "13. **Visualising graphs with the graphviz library:** The code imports necessary libraries and selects a tree to plot. It creates the graph using export_graphviz and displays it.\n",
    "\n",
    "\n",
    "The database employed to illustrate the tools and techniques presented in this Jupyter Notebook is derived from the distinguished article: <i>Chemical Descriptors for a Large-Scale Study on Drop-Weight Impact Sensitivity of High Explosives</i>. This study investigates the relationship between the results of the drop-weight impact testâ€”used to evaluate the handling sensitivity of high explosivesâ€”and a compendium of molecular and chemical descriptors associated with the explosives under examination.\n",
    "\n",
    "<b>Frank W. Marrs, Jack V. Davis, Alexandra C. Burch, Geoffrey W. Brown, Nicholas Lease, Patricia L. Huestis, Marc J. Cawkwell, and Virginia W. Manner, 2023.</b>\n",
    "<i>Chemical Descriptors for a Large-Scale Study on Drop-Weight Impact Sensitivity of High Explosives</i>. <i>Journal of Chemical Information and Modeling.</i><br>\n",
    "https://pubs.acs.org/doi/10.1021/acs.jcim.2c01154<br>\n",
    "<br>\n",
    "\n",
    "**DISCLAIMER:** This code is provided for educational and demonstrative purposes only. Its sole objective is to illustrate Python techniques for data visualisation and analysis. The datasets used in the examples serve purely as illustrative material; no comprehensive or contextual analysis of these specific datasets has been undertaken or is implied. The primary focus remains on the implementation of technical methodologies, rather than the in-depth interpretation of the data itself.\n",
    "For the purposes of this notebook, minor modifications have been introduced into the database in order to facilitate the illustration of certain techniques presented herein.\n",
    "\n",
    "<i>**Fernando GarcÃ­a Bastante<br>\n",
    "Universidade de Vigo**</i>\n",
    "# ........................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a805924-acb0-4fa3-926a-b41b7107f0cc",
   "metadata": {
    "id": "1a805924-acb0-4fa3-926a-b41b7107f0cc"
   },
   "source": [
    "# Setup and Display Options\n",
    "## The first cell of the Jupyter notebook performs some initial setup and imports necessary libraries\n",
    "https://numpy.org/<br>\n",
    "https://pandas.pydata.org/<br>\n",
    "https://matplotlib.org/<br>\n",
    "https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb64fad-4f61-46f2-9528-691968404320",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "editable": true,
    "id": "4cb64fad-4f61-46f2-9528-691968404320",
    "outputId": "1aaf9b43-9afd-46a4-ac56-6f311f126b7c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- Load libraries for data manipulation and visualisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load libraries for data rendering as HTML (optional)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "# Configure pandas and NumPy to enhance DataFrame and array output\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_rows = 1500\n",
    "pd.options.display.max_columns = 300\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d542c5a2-151e-4d20-b8f5-c75b14088b1e",
   "metadata": {
    "id": "d542c5a2-151e-4d20-b8f5-c75b14088b1e"
   },
   "source": [
    "# Excel Data Loading with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6bf61-9d31-4b5c-a9b7-04b1b678e43d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fad6bf61-9d31-4b5c-a9b7-04b1b678e43d",
    "outputId": "121e59d9-076b-4b45-bc25-64cbf8dd6a6d"
   },
   "outputs": [],
   "source": [
    "# ---- Load Dataset from Excel with Error Handling ----\n",
    "file_path = \"data_.xlsx\"\n",
    "sheet_name = \"datasheet\"\n",
    "\n",
    "try:\n",
    "    # Skip the first row which may contain metadata or headers\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1)\n",
    "    print(\"âœ… Data successfully loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: The file '{file_path}' was not found.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"âŒ An unexpected error occurred while loading the file: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb4c27-30c0-414b-a716-a1f6ac27a349",
   "metadata": {
    "id": "58eb4c27-30c0-414b-a716-a1f6ac27a349"
   },
   "source": [
    "# Initial Data Display and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6d6eb-2275-4754-8af5-5f6dfce76f52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "e0d6d6eb-2275-4754-8af5-5f6dfce76f52",
    "outputId": "1b6b105d-5fbb-4c1e-dab5-25e3fe6c2d94",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---- Display the first 5 rows of the DataFrame\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25b89b-eb3e-4d8f-9a9a-b79ff5c1d075",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a25b89b-eb3e-4d8f-9a9a-b79ff5c1d075",
    "outputId": "93d0b043-3246-48d0-89a5-347a52331dc7"
   },
   "outputs": [],
   "source": [
    "# ---- Display information about the DataFrame (rows, columns, data types)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7168780-2d71-4e68-9ee2-7b3b130dd499",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "a7168780-2d71-4e68-9ee2-7b3b130dd499",
    "outputId": "7d964d00-8a79-4138-9013-42426e37e896",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- Display only the names and data types of each column (floats and objects (strings))\n",
    "print(\"Data Types of Each Column:\")\n",
    "print(df.dtypes) # Data type summary\n",
    "print(df.shape) # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97cd9f-c1e7-4dfb-bbba-4998d20a566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----A preliminary overview of the statistics of the target variable\n",
    "df['log H50'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a246a-ec51-4bf3-97f6-ea3eea9a5a70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "ae0a246a-ec51-4bf3-97f6-ea3eea9a5a70",
    "outputId": "480251c8-e244-41b5-a34e-cd0270853dcb"
   },
   "outputs": [],
   "source": [
    "# ----Check the variability of the log H50 measurements for some \"individual\" explosives -> according Chem_Formula\n",
    "df_target_all = df.groupby('Chem_Formula').agg({'log H50': ['count', 'mean', 'std']})  # Get the count, mean and standard deviation for each explosive\n",
    "df_target_all[df_target_all['log H50']['count']>40]  #  Get the mean and std deviation from explosives with a high number of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ea748-27f2-4d84-bdf4-3e68e0ded3a0",
   "metadata": {
    "id": "9b3ea748-27f2-4d84-bdf4-3e68e0ded3a0"
   },
   "source": [
    "# Cleaning Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71fae3-7e0f-45fe-9d4c-25e0db38c39a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b71fae3-7e0f-45fe-9d4c-25e0db38c39a",
    "outputId": "bca7d60d-670f-40e1-a551-dc09b9ef71ba"
   },
   "outputs": [],
   "source": [
    "# -----Clean column names for easier access and scripting ----\n",
    "# Removes leading/trailing spaces, replaces special characters\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()  # Removes any leading, and trailing whitespaces\n",
    "      .str.replace(' ', '_')\n",
    "      .str.replace(r'[(){}\\[\\]]', '', regex=True)\n",
    ")\n",
    "# For stripping all non-alphanumeric characters:\n",
    "# df.columns = df.columns.str.replace(r'[^\\w]', '', regex=True)\n",
    "print(\"ðŸ§¼ Cleaned Column Names:\")\n",
    "print([names for names in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fbda9-7f24-430d-b90f-95e00636501e",
   "metadata": {
    "id": "323fbda9-7f24-430d-b90f-95e00636501e"
   },
   "source": [
    "# Filtering Data: Handling Nulls, Duplicates, Unique-Value Columns, and Irrelevant Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff741e-6723-4f83-b074-34d1a33d091a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "editable": true,
    "id": "7eff741e-6723-4f83-b074-34d1a33d091a",
    "outputId": "13d58d9d-a347-4675-dfe2-a92d00a3dad0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Remove rows (the last ones) and columns (the last one) of NaN's\n",
    "df.dropna(axis='rows', inplace= True, how='all')\n",
    "df.dropna(axis='columns', inplace= True, how='all')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc24daa-2a0d-489c-96aa-4f657102971c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dc24daa-2a0d-489c-96aa-4f657102971c",
    "outputId": "7970c8a4-375f-4efb-bec8-23332eef653c"
   },
   "outputs": [],
   "source": [
    "# ----Only get the data with 'threshold = NaN' and 'group = [NCOO, NOOO, NNOO]\n",
    "df = df[pd.isna(df['threshold'])]\n",
    "df = df[df['group'].isin(['NCOO', 'NOOO', 'NNOO'])]\n",
    "print('Now the dataframe is', df.shape, 'rows x columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d03b6-9962-4c31-a7c3-9c4ce2319757",
   "metadata": {
    "id": "912d03b6-9962-4c31-a7c3-9c4ce2319757"
   },
   "outputs": [],
   "source": [
    "# ----Delete colums of no interest in this exercise\n",
    "df.drop(['id', 'threshold', 'Method', 'reference', 'lab', 'grit'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51525dd-843f-4f51-94a9-e06987b01c02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "d51525dd-843f-4f51-94a9-e06987b01c02",
    "outputId": "8d50e25a-2b0e-4cc1-bbd2-c1e408b42673"
   },
   "outputs": [],
   "source": [
    "# ----Remove duplicated rows: this assumes that the database contains repeated-duplicated values for some tests\n",
    "# If you think all the data is OK comment this code\n",
    "df.drop_duplicates(inplace=True)\n",
    "df[df.duplicated(keep=False)] # checking duplicates again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7623a-0a57-4631-9b39-1cbbf2fb1260",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8e7623a-0a57-4631-9b39-1cbbf2fb1260",
    "outputId": "e1d2dad0-36d3-4ecd-9bb8-d3dcaa649e7e"
   },
   "outputs": [],
   "source": [
    "# ----Check the number of rows and columns after removing duplicates\n",
    "print('Now the dataframe is', df.shape, 'rows x columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b7b63-e38c-44cb-a151-f909c1ee0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Select columns with only one unique value (dummy columns)\n",
    "dummy_col = df.nunique()==1  # Get the column names of unique values\n",
    "dummy_col = dummy_col[dummy_col].index.tolist()  # Get the column names of unique values\n",
    "print(dummy_col)  # Display the dummy columns -you can remove them from df dataframe but we will keep them for now for teaching another way to select them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129f5b6-df8f-4e26-af8d-24246a8081b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "3129f5b6-df8f-4e26-af8d-24246a8081b9",
    "outputId": "976627fd-5dec-4c40-acb9-9b3a54bda844"
   },
   "outputs": [],
   "source": [
    "# ----Other option: check for columns with a known unique value (0, 1 or \"yes\" in this example)\n",
    "no_dummy_col  = (~df.isin([0,1,\"yes\"])).any(axis=0)  # Identify columns with more than one unique value\n",
    "no_dummy_col.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8a81c-322c-4f93-b6ca-7cb33e949586",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "c2a8a81c-322c-4f93-b6ca-7cb33e949586",
    "outputId": "e8be4074-3795-4a01-ccf2-eccdb6814a3a"
   },
   "outputs": [],
   "source": [
    "# ----Remove the \"False\" columns (unique value columns) to keep only informative columns\n",
    "df = df.loc[:, no_dummy_col]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91da88-c788-4882-bdec-cae61822712e",
   "metadata": {
    "editable": true,
    "id": "6b91da88-c788-4882-bdec-cae61822712e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Replace empty cells in columns with NaN missing values for consistency\n",
    "df = df.replace(' ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852fdde-34c5-4a62-b8b5-a582fe80c2fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a852fdde-34c5-4a62-b8b5-a582fe80c2fc",
    "outputId": "1593c614-1433-405e-b5f9-f9cc08fabb76"
   },
   "outputs": [],
   "source": [
    "# ----Count missing values per column\n",
    "missing_data_count = df.isnull().sum()\n",
    "missing_data_percent = 100 * df.isnull().mean()  # Values in percentage\n",
    "\n",
    "# Joining the two series\n",
    "df_ = pd.DataFrame({'missing_data_count': missing_data_count, 'missing_data_percent': missing_data_percent})\n",
    "print(df_[df_['missing_data_count']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dc02a-c1fd-4956-af15-e60024b3e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Fix the missing data in Chem_Formula\n",
    "# Find the NaN Values in Chem_Formula\n",
    "df[df['Chem_Formula'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08998e-a640-4e0e-b8ed-999d9f0172af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Calculate your owns formulas from C, H, N, O and Cl columns in the database (easier option in this example)\n",
    "df[\"Chem_Formula\"] = pd.DataFrame('C' + df[\"C\"].astype(int).astype(str) +\n",
    "                                  'H' + df[\"H\"].astype(int).astype(str) +\n",
    "                                  'N' + df[\"N\"].astype(int).astype(str) +\n",
    "                                  'O' + df[\"O\"].astype(int).astype(str) +\n",
    "                                  'Cl'+ df[\"Cl\"].astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187bb99-fbdb-484f-8a31-1cf617f1bdb2",
   "metadata": {
    "id": "b187bb99-fbdb-484f-8a31-1cf617f1bdb2"
   },
   "outputs": [],
   "source": [
    "# ----Impute missing values in the 'C_v_J_g_K ' column using the mean of the 'C_v_J_g_K' values grouped by 'group'\n",
    "df['C_v_J_g_K'] = df['C_v_J_g_K'].fillna(df.groupby('group')['C_v_J_g_K'].transform('mean'))\n",
    "# df = df.dropna(subset=[\"C_v_J_g_K', \"Chem_Name\"], how=\"any\") # in this case you are removing the rows with NaN values in C_v_J_g_K and Chem_Name columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda52913-63ee-4afa-9c0c-9bc92cc20f81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dda52913-63ee-4afa-9c0c-9bc92cc20f81",
    "outputId": "3f0b6b4f-6306-46fe-ed5a-11d8de0ad547"
   },
   "outputs": [],
   "source": [
    "# ----Checking the number of log_H50 values for each explosive\n",
    "target = 'log_H50'  # log_H50 is the target variable\n",
    "\n",
    "unique_explosives_ = df.groupby('DerivName')[target].count()\n",
    "unique_explosives__ = df.groupby('Chem_Name')[target].count()\n",
    "unique_explosives___ = df.groupby('Chem_Formula')[target].count()\n",
    "print('Number of unique explosives according to DerivName, Chem_Name, Chem_Formula:', unique_explosives_.shape[0], unique_explosives__.shape[0], unique_explosives___.shape[0])\n",
    "print('Explosives with several log_H50 measures according to Chem_Formula')\n",
    "print(unique_explosives___[unique_explosives___>1])  # Perhaps there are no different explosives in the database that have the same Chem_Formula but you must check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6122a-e41f-4f62-9f43-1a768fc03087",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e3f6122a-e41f-4f62-9f43-1a768fc03087",
    "outputId": "b0acf8ff-1252-43c8-c43b-71f4246e19b9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----Display duplicated Chem_Formula values to check if there are different explosives but the same formula (manual labor)\n",
    "df[df['Chem_Formula'].duplicated(keep=False)].sort_values(['Chem_Formula', 'Chem_Name'])  # keep=False shows all duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f23dad-950f-48ea-b2f3-417022c4b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Rename Chem_Formula for different explosives with same formula Example: the 2,3,4_TNT (index=71) and the 2,4,6_TNT (there are a lot of it) have the same formula.\n",
    "# Change the formula of the index 71 adding 'bis':\n",
    "df.loc[71, 'Chem_Formula'] = 'bis' + df.loc[71, 'Chem_Formula']\n",
    "# Now for 2,4,6-Trinitrobenzylalcohol\n",
    "df.loc[120, 'Chem_Formula'] = 'bis' + df.loc[120, 'Chem_Formula']\n",
    "#.................................Do it yourself_________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8df32-c771-40be-9e2a-419d5c0e4aa7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "ae0a246a-ec51-4bf3-97f6-ea3eea9a5a70",
    "outputId": "480251c8-e244-41b5-a34e-cd0270853dcb"
   },
   "outputs": [],
   "source": [
    "# ----Check the variability of the log_H50 measurements for individual explosives\n",
    "df_target_st = df.groupby('Chem_Formula').agg({target: ['count', 'mean', 'std']})  # Get the count, mean and standard deviation for each explosive\n",
    "df_target_st[df_target_st[target]['count']>25]  #  Get the mean and std deviation from explosives with a high number of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ff51d-d68e-44ff-bc41-39347d758392",
   "metadata": {
    "id": "032ff51d-d68e-44ff-bc41-39347d758392"
   },
   "source": [
    "# Creating New Features and Changing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437e5c5-0e48-4d99-9993-3f5f7e6bf2af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "a437e5c5-0e48-4d99-9993-3f5f7e6bf2af",
    "outputId": "1ac09ea2-1d33-47d5-a513-082b13dd06fa"
   },
   "outputs": [],
   "source": [
    "# ----Add a new feature\n",
    "df[\"q_per_mol\"] = df[\"q_per_g\"]/df[\"gas_moles_per_g\"]\n",
    "# Change the type to string to show later how to convert strings to numbers\n",
    "df.q_per_mol = df.q_per_mol.astype('string') # Convert column 'q_per_mol' to string type\n",
    "df[\"q_per_mol\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e5c97-3ce7-4d20-83ba-a414fb2590e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "367e5c97-3ce7-4d20-83ba-a414fb2590e7",
    "outputId": "e8704b94-82b0-462a-a8f9-bfd53ea56eb5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Display the data types of each column\n",
    "print(\"Data Types of Each Column:\")\n",
    "print(df.dtypes)\n",
    "print(df.shape) # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613b4f5-9f70-4161-8e29-8f107e8403ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "6613b4f5-9f70-4161-8e29-8f107e8403ae",
    "outputId": "0b005bcf-8c9f-4c9c-95e1-e3a0e9976b84",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Case you need to convert relevant columns to numeric if they aren't already\n",
    "numeric_convert_columns = [\"q_per_mol\"] # only this column in this example\n",
    "df[numeric_convert_columns] = df[numeric_convert_columns].apply(pd.to_numeric, errors='coerce', downcast=\"float\") # coerce invalid parsing will be set as NaN\n",
    "df[\"q_per_mol\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31d44f-6af2-4942-8cb9-a02587f2187f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb31d44f-6af2-4942-8cb9-a02587f2187f",
    "outputId": "0f40e0f1-2fb5-4c61-f473-c8d6c0dcf7ee"
   },
   "outputs": [],
   "source": [
    "# ----Surely be this one alternative a better option:\n",
    "df[\"q_per_mol\"] = df[\"q_per_mol\"].values.astype(float)  # Convert 'q_per_mol' to float type\n",
    "df[\"q_per_mol\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f23198-f73e-4527-acbd-b0b038044a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Define your own new feature\n",
    "#df[''] = df['']\n",
    "#df[''].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf7158-3145-40dc-ac36-34806870691b",
   "metadata": {},
   "source": [
    "#  Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc813e-109f-489c-99e3-e90a6512c769",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "fcfc813e-109f-489c-99e3-e90a6512c769",
    "outputId": "eb2efc3c-fc76-4744-fb41-afdb44432d66"
   },
   "outputs": [],
   "source": [
    "# ----Label Encoding: transform a categorical variable (group) into numeric using factorize function\n",
    "df['num_type'], uniques = pd.factorize(df['group']) # Create a numerical representation of the 'group' column\n",
    "df['num_type'].head(10) # Display the first 15 values of the 'num_type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a97d15-e85f-4daf-b4e5-cd9e41a72f20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69a97d15-e85f-4daf-b4e5-cd9e41a72f20",
    "outputId": "cbbe79ce-caf3-4c0e-a7e5-3a060ea3a121"
   },
   "outputs": [],
   "source": [
    "# ----Display the Type variable (num_type 0:NOOO, num_type 1:NCOO...)\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e039b-c928-40e3-a764-089684d64087",
   "metadata": {
    "id": "8a6e039b-c928-40e3-a764-089684d64087"
   },
   "outputs": [],
   "source": [
    "# ----Custom mapping: it is appropriate to map according to some ordinal criteria, e.g. from lower to higher average sensitivity of the functional group\n",
    "custom_map = {'NCOO': 1, 'NNOO': 0, 'NOOO': -1}\n",
    "df['num_type'] = df['group'].map(custom_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LbKzPHR0rft1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "LbKzPHR0rft1",
    "outputId": "de016f94-c265-4205-c016-d150d38a6f56"
   },
   "outputs": [],
   "source": [
    "# ----Using one hot encoding is other option\n",
    "my_groups = pd.get_dummies(df['group'])  # Only need n-1 codes: pd.get_dummies(df['group'], drop_first=True)\n",
    "df_ = pd.concat([df, my_groups], axis=1)\n",
    "df_[uniques].head(10)  # Note that there are different columns with repeated names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3653e4d-2862-40c7-afea-c95b81c7fda9",
   "metadata": {},
   "source": [
    "# Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb199aa-c589-4686-b526-904a3de45fa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "7fb199aa-c589-4686-b526-904a3de45fa6",
    "outputId": "d4e35619-639c-43d8-d6c8-3b806dfacb5a"
   },
   "outputs": [],
   "source": [
    "# ----Basic statistics with pandas\n",
    "df.describe() # Explore the variant: df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f8b52-5ef6-4682-b76e-bd3a8352c3de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "551f8b52-5ef6-4682-b76e-bd3a8352c3de",
    "outputId": "13afeeb2-6e0a-469a-f1ee-35f345e0ca83",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----In case you need only the mean values...\n",
    "print('----------------Average values')\n",
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69fe760-149f-42e6-a547-d11d6037ee36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e69fe760-149f-42e6-a547-d11d6037ee36",
    "outputId": "31c83072-5062-449a-97d4-1763a469fe89"
   },
   "outputs": [],
   "source": [
    "# ----Checking the number of lnH50 values for each group\n",
    "print('------------- All values: there are several repeated explosives ------------')\n",
    "print('------ data number by', df.groupby('group')[target].count())\n",
    "print('------ mean value by', df.groupby('group')[target].mean())\n",
    "print('------ standard value by', df.groupby('group')[target].std())\n",
    "print('------ aprox. number of unique explosives (according Chem_Formula) by', df.groupby('group')['Chem_Formula'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676451a-5243-42dc-bc19-7af88731d2c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "6676451a-5243-42dc-bc19-7af88731d2c0",
    "outputId": "80d2da35-b018-4828-eb8c-79d155bee138",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Get the numeric and the \"categorical\" features names\n",
    "num_columns = [col for col in df.select_dtypes(include=[np.number]).columns]\n",
    "cat_columns = [col for col in df.select_dtypes(include=[object]).columns]\n",
    "print(num_columns)\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13ac6c-3b18-4a17-a685-087fb4e660c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "editable": true,
    "id": "0b13ac6c-3b18-4a17-a685-087fb4e660c4",
    "outputId": "9a2ac820-16f3-471d-aa52-69fd27eac7c2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Make a dataframe with the numerical columns\n",
    "num_df=df[num_columns]\n",
    "num_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61998a-52d1-4fda-bd1d-86be82e34fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba61998a-52d1-4fda-bd1d-86be82e34fef",
    "outputId": "2321e7dd-acb9-432a-d7e3-61ca4b5d2d01"
   },
   "outputs": [],
   "source": [
    "# ----Checking the types\n",
    "print(num_df.dtypes.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4024b8-8a39-4046-8e06-db2d8097ae2e",
   "metadata": {
    "id": "ef4024b8-8a39-4046-8e06-db2d8097ae2e"
   },
   "source": [
    "## Standardised Features, Search for Outliers and Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32cf47-58c8-453f-8839-b9164c320917",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a32cf47-58c8-453f-8839-b9164c320917",
    "outputId": "73e50344-9e02-47d9-f058-ac6b3b357df7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----Standardized values\n",
    "std_num = (num_df - num_df.mean()) / num_df.std()  # Calculate the standarised values\n",
    "std_df = pd.concat([std_num, df[cat_columns]], axis=1)  # Add the non-numeric columns\n",
    "print(std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b3908-991c-4da4-b8ff-29a3dd92d75a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "822b3908-991c-4da4-b8ff-29a3dd92d75a",
    "outputId": "e69c87ef-6a36-4144-82fc-92e1f2677d21"
   },
   "outputs": [],
   "source": [
    "# ----Check the variability of the standardised target measurements\n",
    "print(' Data for standardised values of target')\n",
    "std_df[target].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f5207-72a1-499a-9a2c-eea5d97c706d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a76f5207-72a1-499a-9a2c-eea5d97c706d",
    "outputId": "592ee601-57f9-4925-e027-84ac8a490745",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----Check for outliers in numeric columns [later we will draw boxplots to get the outliers graphically]\n",
    "# An outlier is defined as an observation that deviates significantly from other values in a dataset, which does not inherently indicate an error or incorrectness\n",
    "\n",
    "# Method a- with 3 standard deviations in this example]\n",
    "std_dev_limit = 3 # Set the standard deviation limit for outlier detection\n",
    "df_outlier = std_df[std_df[num_columns].abs()>std_dev_limit] # Identify outliers based on standard deviation only in the [num_columns]\n",
    "\n",
    "# Number of ouliers in each column (NaN's in df_outlier dataframe are non-outlier values)\n",
    "df_outlier.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697d7eb-7396-450b-9065-df1341a2f84f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "5697d7eb-7396-450b-9065-df1341a2f84f",
    "outputId": "bf7ef3c1-1a68-4b79-d8c2-4415ba76efcd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- Method b- with 1.5 IQR\n",
    "def check_outliers(column, df=df):\n",
    "    \"\"\"\n",
    "    Identifies outliers in a given column using the Interquartile Range (IQR) method.\n",
    "    Args:\n",
    "        column (str): The name of the column to check for outliers.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the rows identified as outliers.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25) # Calculate the first quartile\n",
    "    Q3 = df[column].quantile(0.75) # Calculate the third quartile\n",
    "    IQR = Q3 - Q1 # Calculate the third quartile\n",
    "    lower_bound = Q1 - 1.5 * IQR # Calculate the lower bound for outliers\n",
    "    upper_bound = Q3 + 1.5 * IQR # Calculate the upper bound for outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]  # Identify outliers\n",
    "    return outliers\n",
    "# Check the outliers for each column in the dataframe\n",
    "for col in num_columns:\n",
    "    outliers = check_outliers(col)\n",
    "    if not outliers.empty:\n",
    "        print(f\"\\nOutliers in {col}:\")\n",
    "        print(outliers[\"Chem_Formula\"]) # Print the 'Chem_formula' of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ef24e-1868-4fcf-bdf0-e1c590ed1e1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "a98ef24e-1868-4fcf-bdf0-e1c590ed1e1b",
    "outputId": "99dadcbc-3d3b-4810-b10c-c08cc0740590"
   },
   "outputs": [],
   "source": [
    "# ----Check the variability of the standardised target measurements for individual explosives\n",
    "std_group_target = std_df.groupby('Chem_Formula').agg({target: ['count', 'mean', 'std']})  # Get the count, mean and deviation for each explosive\n",
    "print('Calculated from standardised values')\n",
    "std_group_target[std_group_target[target]['count']>25]  #  Get the std deviation only from a high number of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0747ad-f468-42cb-8a15-51b29f55c5aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf0747ad-f468-42cb-8a15-51b29f55c5aa",
    "outputId": "f8bbc40b-eacf-48dd-bc4f-67564f0f8c9e"
   },
   "outputs": [],
   "source": [
    "# ----Let's group the df original dataframe by 'Chem_Formula' using the mean of log_H50 as the target variable\n",
    "#  std_df[target] = df[target]  # Works with log_H50 to facilitate interpretation\n",
    "dic_column_names = {col: 'first' for col in df.columns.drop('Chem_Formula')}  # Get the columns names and operator to apply for each (save the first value)\n",
    "dic_column_names[target] = 'mean'  # Change the operator to mean for target column\n",
    "u_df = df.groupby('Chem_Formula').agg(dic_column_names).reset_index()  #  Create the new datafrmae with unique explosives\n",
    "print(u_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f3ecf-02de-4824-8251-40351456646b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "1f1f3ecf-02de-4824-8251-40351456646b",
    "outputId": "f0b8f241-bc39-47a0-8d97-0567e5ac1caa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic statistics of grouped data by explosive (non_standardised data)\n",
    "u_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6f569-6e15-4a6e-9c6e-cb55ea2bd1f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8bf6f569-6e15-4a6e-9c6e-cb55ea2bd1f5",
    "outputId": "f293fb98-a359-41ad-a2cc-1102b46fe2a6"
   },
   "outputs": [],
   "source": [
    "# ----Check the variability of log_H50 measurements for each group (non-standardised)\n",
    "df_target = u_df.groupby('group').agg({target: ['count', 'mean', 'std']})  # Get the count, mean and standard deviation for each group\n",
    "df_target[df_target[target]['count']>25]  #  Get the std deviation from a high number of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3fb5c-7bd8-4d24-9e9d-84148865e642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "b3d3fb5c-7bd8-4d24-9e9d-84148865e642",
    "outputId": "e41cf81a-0a6f-4ad1-f2a3-4b2b5996900b"
   },
   "outputs": [],
   "source": [
    "# ----Standardized values except log_H50 and num_type\n",
    "u_std_df = (u_df[num_columns] - u_df[num_columns].mean()) / u_df[num_columns].std()\n",
    "u_std_df[target] = u_df[target]  # Works with log_H50 instead of stardrdised values to facilitate interpretation\n",
    "u_std_df['num_type'] = u_df['num_type']\n",
    "u_std_df = pd.concat([u_std_df, u_df[cat_columns]], axis=1)  # Add the non-numeric columns\n",
    "u_std_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63a094-72d1-47c2-bfac-1dbff33d73fe",
   "metadata": {
    "id": "5b63a094-72d1-47c2-bfac-1dbff33d73fe"
   },
   "source": [
    "## Correlations between features\n",
    "\n",
    "### The target is lnH50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41499b3e-dbfd-45b5-bacb-536525b6b7a2",
   "metadata": {
    "editable": true,
    "id": "41499b3e-dbfd-45b5-bacb-536525b6b7a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Get a dataframe with the most correlated features with the variable 'lnH50'\n",
    "def analyze_imp_correlations(df, number):\n",
    "    \"\"\"\n",
    "    Analyses and selects the top correlated features with the target variable 'lnH50'.\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "        number (int): The number of top correlated features to select.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the selected features and the target variable.\n",
    "    \"\"\"\n",
    "    imp_corr = df.corr(numeric_only=True)[target].abs().sort_values(ascending=False) # Calculate correlations with 'ln_H50'\n",
    "    top_correlated_vars = imp_corr[1:number].index.tolist() # Select top correlated features\n",
    "    top_correlated_vars.insert(0, target) # Add 'lnH50' to the list\n",
    "    top_correlated_vars.extend(['group', 'Chem_Formula']) # insert the num_type feature to the end of the list\n",
    "    # top_correlated_vars.remove('H50') # remove the H50 feature\n",
    "    return df[top_correlated_vars] # Return a DataFrame with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ff39e-653b-4175-b7e9-c08f0fe23a00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "6a1ff39e-653b-4175-b7e9-c08f0fe23a00",
    "outputId": "467b6a40-6400-4716-dcc3-a6dfd8608f36",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Choose the number of most correlated features to analyze and apply 'analyze_imp_correlations(df, number)'\n",
    "max_number_correlated = 15\n",
    "correlated_df = analyze_imp_correlations(u_std_df, max_number_correlated+1) # Get the DataFrame with top correlated features\n",
    "print(f\"\\nDataframe with the {max_number_correlated} most correlated features with the target variable lnH50\")\n",
    "print(correlated_df.head(3))\n",
    "print('......................................................................................................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605df17-6ec3-442a-8b3e-c5979b547500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "8605df17-6ec3-442a-8b3e-c5979b547500",
    "outputId": "bb9c124d-42bd-47b1-b973-591e3772b3c0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Correlation Analysis: compute correlation matrix for key parameters\n",
    "correlation_matrix = correlated_df.corr(numeric_only=True)\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40c0b1-33fc-4911-81ac-2f8d7a091a3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "editable": true,
    "id": "3f40c0b1-33fc-4911-81ac-2f8d7a091a3a",
    "outputId": "e7b58e50-0843-4104-8a84-db819b79ff3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True) # Create a heatmap of the correlation matrix\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show() # Display the heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00def095-bcca-43c8-b7a9-3a4f6006fcbe",
   "metadata": {
    "id": "00def095-bcca-43c8-b7a9-3a4f6006fcbe"
   },
   "source": [
    "## Distribution Plots of Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2250a1d-07c4-4149-ab7d-da7ffe09aa78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "b2250a1d-07c4-4149-ab7d-da7ffe09aa78",
    "outputId": "0dd8d1af-32eb-4f0f-c644-a9c6218842fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Distribution plots of key parameters\n",
    "number_keys = 5  #  Select the number of key parameters to plot\n",
    "for param in correlated_df.columns[0:number_keys]:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(u_std_df[param], kde=True, bins=20, color=\"blue\") # Note that this example use standardized data\n",
    "    plt.title(f\"Distribution of standardized {param}\")\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc1be1-f3b7-4348-af5e-58a67a101614",
   "metadata": {
    "id": "5efc1be1-f3b7-4348-af5e-58a67a101614"
   },
   "source": [
    "## Box plots to visualise the dispersion of key parameters and identify possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf6437-5870-43f4-9518-9285e7cebc11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "28bf6437-5870-43f4-9518-9285e7cebc11",
    "outputId": "75f86e7f-16d8-464a-e1b1-b4db5df808ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Boxplots for key parameters to visualize spread and identify potential outliers\n",
    "for param in correlated_df.columns[0:number_keys+1]:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=correlated_df, x=param) # Note that this example use correlated_df (standardized) data\n",
    "    if param != 'log_H50':\n",
    "        plt.title(f\"Boxplot of {param} standardized\")\n",
    "    else:\n",
    "        plt.title(f\"Boxplot of {param}\")\n",
    "    plt.xlabel(param)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc91a2-7de6-4df7-bcad-4c4afd7baa9d",
   "metadata": {
    "id": "f9cc91a2-7de6-4df7-bcad-4c4afd7baa9d"
   },
   "source": [
    "## Trend Analysis to visualise correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72420461-bf75-4fff-97ca-d546fd65c99d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "72420461-bf75-4fff-97ca-d546fd65c99d",
    "outputId": "6316aa14-8201-4d26-c5e7-4661ebd58b35",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Plot trends of `log_H50` vs features in correlated_df\n",
    "for param in correlated_df.columns[1:number_keys+1]:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(data=correlated_df, x=param, y=target, hue='q_per_g', size='group', palette='viridis') #Note that standardised data are used here\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(target)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Compound legend\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fa972-4ce7-4057-a6c5-8b14f3e3b318",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "4d6fa972-4ce7-4057-a6c5-8b14f3e3b318",
    "outputId": "ee3addb8-7535-40d3-cf96-f8fa29373f50",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Pairplot for visualizing relationships between key features\n",
    "sns.pairplot(data=correlated_df, diag_kind='kde', hue='group', palette='Set2')\n",
    "plt.suptitle(\"Pairplot of Key Parameters\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259ec74-3a80-4bf9-8d59-ab7179901ef9",
   "metadata": {
    "id": "a259ec74-3a80-4bf9-8d59-ab7179901ef9"
   },
   "source": [
    "## Summary of findings, saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66230b9b-0149-4979-bd70-4ad1ca295bee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66230b9b-0149-4979-bd70-4ad1ca295bee",
    "outputId": "7dbd56fa-1dd1-463c-af82-9b4a7420ea9f"
   },
   "outputs": [],
   "source": [
    "# ----Select the features to save\n",
    "feat_select = ['Chem_Name'] + [i for i in  correlated_df.columns[0:4]] + ['group']\n",
    "\n",
    "# Creating tables for saving\n",
    "summary_table_low_imp = u_std_df[feat_select].sort_values(by=target, ascending=True).head(10)  # Dataframe for compounds with high impact sensitivity\n",
    "summary_table_high_imp = u_std_df[feat_select].sort_values(by=target, ascending=False).head(10)  # Dataframe for compounds with low impact sensitivity\n",
    "\n",
    "# Display the tables\n",
    "print(\"\\nTop 10 Compounds with the Highest Impact Sensitivity (`log_H50`):\")\n",
    "print(summary_table_low_imp)\n",
    "print(\"\\nTop 10 Compounds with the Lowest Impact Sensitivity (`log_H50`):\")\n",
    "print(summary_table_high_imp)\n",
    "\n",
    "# Save processed data to a new Excel file\n",
    "output_file_path = \"processed_data_analysis.xlsx\"\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name=\"Processed_Data\", index=False)  # Save processed data to a sheet named 'Processed_Data'\n",
    "    summary_table_low_imp.to_excel(writer, sheet_name=\"Summary_Table_Low_Imp\", index=False)  # Save high impact sensitivity data to a separate sheet\n",
    "    summary_table_high_imp.to_excel(writer, sheet_name=\"Summary_Table_High_Imp\", index=False)  # Save low impact sensitivity data to a separate sheet\n",
    "\n",
    "print(f\"\\nProcessed data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec181875-1773-462e-90e1-0c7631b22e2b",
   "metadata": {
    "id": "ec181875-1773-462e-90e1-0c7631b22e2b"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b0d88-dde5-434f-98e0-8384b08a90b1",
   "metadata": {
    "id": "553b0d88-dde5-434f-98e0-8384b08a90b1"
   },
   "source": [
    "## Classical Linear Regression\n",
    "https://www.statsmodels.org/dev/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb753a-a654-486c-a331-72a1e3e86ea6",
   "metadata": {
    "id": "73eb753a-a654-486c-a331-72a1e3e86ea6"
   },
   "outputs": [],
   "source": [
    "# ----Linear regression fitting with statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor # for checking correlation effects betwen features\n",
    "from statsmodels.tools.eval_measures import rmse # for getting the root mean squared error\n",
    "from statsmodels.stats.dist_dependence_measures import distance_correlation  # for calculate the distance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98b358-ef74-4579-a9ab-e0241dd69cd3",
   "metadata": {
    "editable": true,
    "id": "8d98b358-ef74-4579-a9ab-e0241dd69cd3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----Getting the features and the target variable\n",
    "X_features = correlated_df.drop([target, 'group', 'Chem_Formula'], axis = 1) # Only the numeric values\n",
    "y = correlated_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bfcb9-70db-4b1c-94d2-7f7d7cdedac8",
   "metadata": {},
   "source": [
    "### Before fitting the model, we are going to calculate the distance_correlation between features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89abab-bc9a-4a6a-8f74-1d533ba00194",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "ed89abab-bc9a-4a6a-8f74-1d533ba00194",
    "outputId": "b3ae9880-65e6-45a8-dd58-5cfaa0668ab5"
   },
   "outputs": [],
   "source": [
    "# ----Calculate the distance correlation for each feature with the target variable (best than Pearson for non linear correlation)\n",
    "distance_correlations = {}\n",
    "for col in X_features.columns:\n",
    "    d_corr = distance_correlation(X_features[col], y)\n",
    "    distance_correlations[col] = d_corr\n",
    "\n",
    "# Sort the features by distance correlation in descending order\n",
    "sorted_distance_correlations = sorted(distance_correlations.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Extract feature names and their distance correlations for plotting\n",
    "features = [item[0] for item in sorted_distance_correlations]\n",
    "dCorrelations = [item[1] for item in sorted_distance_correlations]\n",
    "\n",
    "# Calculate the distance correlation using all the features with the target variable\n",
    "dCorr_all_features = distance_correlation(X_features, y)\n",
    "print('the distance correlation calculated using all features is', f'{dCorr_all_features:0.2f}')\n",
    "\n",
    "# Create a bar plot of the distance correlations\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=dCorrelations, y=features)\n",
    "plt.title(f'Distance Correlation with {target}')\n",
    "plt.xlabel('Distance Correlation')\n",
    "plt.ylabel('Features')\n",
    "\n",
    "# Add the distance correlation values as text labels on the bars\n",
    "for index, value in enumerate(dCorrelations):\n",
    "    ax.text(value, index, f'{value:.2f}', va='center') # Using ax.text to place text\n",
    "\n",
    "plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b222f8-1626-44e4-a6bc-217fea0260f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Checking the features combination with the highest distance correlation with the target variable\n",
    "import itertools\n",
    "feat_number = 4 # Number of features to combine\n",
    "combi = list(itertools.combinations(features[0:15], feat_number))\n",
    "dist_corr = [(select_features, distance_correlation(X_features[list(select_features)], y)) for select_features in combi]  # Calculate the distance correlation for each pair of features\n",
    "dist_corr = pd.DataFrame(dist_corr, columns=['features', 'distance_correlation']).sort_values('distance_correlation', ascending=False)\n",
    "print(dist_corr.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635fdc8-6d2d-42e3-9037-6e488410e929",
   "metadata": {
    "id": "a635fdc8-6d2d-42e3-9037-6e488410e929"
   },
   "outputs": [],
   "source": [
    "# ----Begin the regression analysis\n",
    "# Add a constant term to X_features for the intercept\n",
    "X0 = sm.add_constant(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787669e-6a7c-499a-9046-f02879bbbbe1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2787669e-6a7c-499a-9046-f02879bbbbe1",
    "outputId": "7d863018-32a9-403e-9ff3-cf35896b80a5"
   },
   "outputs": [],
   "source": [
    "print(X0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cafc656-4d87-48f4-837c-80f0ec235190",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cafc656-4d87-48f4-837c-80f0ec235190",
    "outputId": "9b43fba3-3a50-4070-d503-4ab18b8af486"
   },
   "outputs": [],
   "source": [
    "# ----Fit the model\n",
    "model = sm.OLS(y, X0).fit()  # Fit an Ordinary Least Squares (OLS) regression model\n",
    "print(model.summary(alpha = 0.05))  # Print the model summary\n",
    "print(f'The rmse is: {rmse(y, model.predict(X0)):.2f}') # Print the root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8caefb8-abe6-45b0-8b17-3e52ce8f2805",
   "metadata": {
    "id": "c8caefb8-abe6-45b0-8b17-3e52ce8f2805"
   },
   "outputs": [],
   "source": [
    "# ----Function for drawing a y-ypredict scatterplot\n",
    "def plot_scatter (y_predict, y=y):\n",
    "    \"\"\"\n",
    "    Creates a scatterplot of predicted values (y_predict) against actual values (y).\n",
    "    Args:\n",
    "        y_predict (array-like): Predicted values.\n",
    "        y (array-like, optional): Actual values. Defaults to the global 'y' variable.\n",
    "    \"\"\"\n",
    "    residuals = np.abs(y-y_predict)  # Calculate residuals\n",
    "    threshold = 3 * np.std(residuals)  # setting a threshold to identify possible outliers\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_aspect('equal')\n",
    "    sns.scatterplot(x=y_predict, y=y)  # Create a scatterplot\n",
    "    sns.scatterplot(x=y_predict[abs(residuals) > threshold], y=y[residuals > threshold], color='red', label='Outliers?')  # Highlight potential outliers\n",
    "    xmin, xmax = y_predict.min() -.25, y_predict.max() +.25\n",
    "    sns.lineplot(x=[xmin, xmax], y=[xmin, xmax], color='green')\n",
    "    plt.title(f\"Impact Sensitivity prediction\")\n",
    "    plt.xlabel('y_predict')\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('Pearson correlation matrix:')\n",
    "    print(np.corrcoef(y, y_predict))  # Print the Pearson correlation matrix\n",
    "    print(f'The rmse is: {rmse(y, y_predict):.2f}')  # Print the rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c627b-93af-4b26-b418-293725f16215",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "f92c627b-93af-4b26-b418-293725f16215",
    "outputId": "603d00cb-cbb4-40d0-9df9-fbf503821854"
   },
   "outputs": [],
   "source": [
    "# ----Create a scatterplot of predicted vs actual values\n",
    "y0_predict = model.predict(X0)\n",
    "plot_scatter(y0_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba1f9a-e70b-4d2d-afb7-4eae7f49ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Function for drawing a residuals Box-Plot\n",
    "def plot_residuals_by_class(df, residuals_col, group_col=None, title=\"Residuals Box Plots\",\n",
    "                            xlabel=None, ylabel=\"Residuals\"):\n",
    "    \"\"\"\n",
    "    Generates boxplots of residuals, either grouped by a specified column or\n",
    "    as a single boxplot for all residuals if no group column is provided.\n",
    "    Calculates and displays the RMSE for each group (or overall) directly on the plot.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the residual values and optionally the group column.\n",
    "    residuals_col : str\n",
    "        The name of the column in 'df' that contains the residual values.\n",
    "    group_col : str, optional\n",
    "        The name of the column in 'df' that contains the group (class) labels.\n",
    "        If None, a single boxplot for all residuals will be generated. Defaults to None.\n",
    "    title : str, optional\n",
    "        Main title for the plot. Defaults to \"Residuals Boxplots\".\n",
    "    xlabel : str, optional\n",
    "        Label for the X-axis. If 'group_col' is provided, defaults to the group_col name.\n",
    "        If 'group_col' is None, it won't be displayed. Defaults to None.\n",
    "    ylabel : str, optional\n",
    "        Label for the Y-axis. Defaults to \"Residuals\".\n",
    "    \"\"\"\n",
    "\n",
    "    if residuals_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{residuals_col}' not found in the DataFrame.\")\n",
    "\n",
    "    # --- Calculate RMSE ---\n",
    "    if group_col:\n",
    "        rmse_values = df.groupby(group_col)[residuals_col].apply(lambda x: np.sqrt(np.mean(x**2)))\n",
    "        print(\"RMSE per Group:\")\n",
    "        [print(f\"  Group {name}: {value:.3f}\") for name, value in rmse_values.items()]\n",
    "\n",
    "    # Calculate overall RMSE\n",
    "    overall_rmse = np.sqrt(np.mean(df[residuals_col]**2))\n",
    "    all_rmse_values = pd.Series({'All Data': overall_rmse}) # Wrap in Series for consistent handling\n",
    "    print(f\"Overall RMSE: {overall_rmse:.3f}\")\n",
    "\n",
    "    # --- Plotting Setup ---\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # --- Create Boxplots ---\n",
    "    if group_col:\n",
    "        sns.boxplot(hue=group_col, y=residuals_col, data=df, hue_order=rmse_values.index.tolist(), notch=True, gap=.1)\n",
    "        # Default xlabel to group_col name if not explicitly set\n",
    "        if xlabel is None:\n",
    "            xlabel = group_col\n",
    "    else:\n",
    "        # Single boxplot for all data\n",
    "        sns.boxplot(y=residuals_col, data=df, flierprops=dict(markerfacecolor='0.7', markersize=5))\n",
    "        # No xlabel needed for a single boxplot\n",
    "        if xlabel is None:\n",
    "            xlabel = \"\" # Empty string to remove label\n",
    "\n",
    "    # --- Add Titles and Labels ---\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.yticks(fontsize=10)\n",
    "\n",
    "    # --- Annotate with RMSE values ---\n",
    "    if group_col:\n",
    "        for i, group_name in enumerate(rmse_values.index):       \n",
    "            rmse_value = rmse_values[group_name]\n",
    "            plt.text(-0.3+0.3*i, - 1.2, f'RMSE: {rmse_value:.3f}',\n",
    "                 horizontalalignment='center', color='black', weight='semibold', fontsize=14)\n",
    "    else:\n",
    "        # 'x' position for a single boxplot is 0\n",
    "        plt.text(0, -1.2, f'Overall RMSE: {overall_rmse:.3f}',\n",
    "                 horizontalalignment='center', color='black', weight='semibold', fontsize=12)\n",
    "\n",
    "    # --- Final Touches ---\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fb21c-554d-4c0f-9044-1d8d3dbc8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Box-Plot\n",
    "u_std_df['residuals_0'] = y-y0_predict  # Add the residuals to the unique explosives dataframe \n",
    "plot_residuals_by_class(u_std_df, residuals_col='residuals_0', group_col='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0050d554-211a-4a7c-bb8e-8a0fd343756d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "0050d554-211a-4a7c-bb8e-8a0fd343756d",
    "outputId": "c79a8959-50e0-4cb9-f1f8-2b4675e0308e"
   },
   "outputs": [],
   "source": [
    "# ----Checking variance inflation factor (VIF < 5(10))\n",
    "pd.Series([variance_inflation_factor(X0.values, i) for i in range(X0.shape[1])], index=X0.columns)  # Calculate and display VIF for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969307a-a184-4734-9e5b-fda5de0895b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "7969307a-a184-4734-9e5b-fda5de0895b9",
    "outputId": "a265cd57-9419-4691-dc9c-d7ed0d86a0cf"
   },
   "outputs": [],
   "source": [
    "# Removing some features and checking VIF again\n",
    "features_to_remove = ['NOO',\n",
    "                     'Atom_E_atom',\n",
    "                     'remain_O2',\n",
    "                     'q_per_mol',\n",
    "                     'NO',\n",
    "                     'Moment2',\n",
    "                     'NO_group'\n",
    "                      ]\n",
    "X1 = X0.drop(features_to_remove, axis = 1) # New X dataframe\n",
    "pd.Series([variance_inflation_factor(X1.values, i) for i in range(X1.shape[1])], index=X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cc3e6-7240-4bd4-bcdd-190234734b84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69cc3e6-7240-4bd4-bcdd-190234734b84",
    "outputId": "56e1c2db-a236-4809-8a47-dadee597ddd6"
   },
   "outputs": [],
   "source": [
    "# Fitting the new model\n",
    "model1 = sm.OLS(y, X1).fit()  # Fit a new OLS regression model\n",
    "print(model1.summary(alpha = 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5480dc0-4cb3-4c21-8e37-75d3891d80e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5480dc0-4cb3-4c21-8e37-75d3891d80e8",
    "outputId": "725e69a1-f34b-4396-fafc-827e5b22ea03"
   },
   "outputs": [],
   "source": [
    "# Removing the const... features and Fitting the new model\n",
    "X1 = X1.drop(['gas_C', 'gas_CO2'], axis = 1)\n",
    "model1 = sm.OLS(y, X1).fit()\n",
    "print(model1.summary(alpha = 0.05))  # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556f31b-7e3e-4c38-b934-7ca05b1f3942",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "7556f31b-7e3e-4c38-b934-7ca05b1f3942",
    "outputId": "d7f24c7a-90ec-40cd-dda6-0b07564d2603"
   },
   "outputs": [],
   "source": [
    "# Drawing the sscatterplot y-y_predict\n",
    "y1_predict = model1.predict(X1)\n",
    "plot_scatter(y1_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9dd19-c4f5-4a84-9e40-4503c7d67a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Box-Plot\n",
    "u_std_df['residuals_1'] = y-y1_predict  # Add the residuals to the unique explosives dataframe \n",
    "plot_residuals_by_class(u_std_df, residuals_col='residuals_1', group_col='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c05d3-620c-4b63-948a-f0b8c867794a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "158c05d3-620c-4b63-948a-f0b8c867794a",
    "outputId": "e62f95c0-afe4-4343-fa8d-08d78fc795a0"
   },
   "outputs": [],
   "source": [
    "# Creating regression plots for visualizing the relationship between features and the target variable\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "fig = sm.graphics.plot_regress_exog(model1, 'q_per_g', fig=fig)  # Create a regression plot for the 'Q' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabfc0d-d708-4234-b392-8132c02f77f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "7aabfc0d-d708-4234-b392-8132c02f77f9",
    "outputId": "1c08aaf6-fca1-4ef6-ea0f-d171835f716a"
   },
   "outputs": [],
   "source": [
    "# Creating regression plots\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "fig = sm.graphics.plot_regress_exog(model1, 'Moment1', fig=fig)  # Create a regression plot for the 'Cs' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72f4af-2ed9-4349-baa1-afd4425792e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "1e72f4af-2ed9-4349-baa1-afd4425792e0",
    "outputId": "c5072b4f-e669-4ce4-9754-383fd5be2e7b"
   },
   "outputs": [],
   "source": [
    "# Checking variance inflation factor (VIF < 5(10)) to assess multicollinearity\n",
    "pd.Series([variance_inflation_factor(X1.values, i) for i in range(X1.shape[1])], index=X1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb10c4-4c72-4a73-8cd8-10b5c2607b5e",
   "metadata": {
    "id": "24eb10c4-4c72-4a73-8cd8-10b5c2607b5e"
   },
   "source": [
    "## Stepwise regression technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726342ac-f965-46f1-a7da-6b11621e94e8",
   "metadata": {
    "id": "726342ac-f965-46f1-a7da-6b11621e94e8"
   },
   "outputs": [],
   "source": [
    "# Function for adding and selecting features by steps according to aic/bic criteria\n",
    "def stepwise_selection(X, y):\n",
    "    \"\"\"\n",
    "    Performs stepwise feature selection using AIC/BIC criteria.\n",
    "    Args:\n",
    "        X (pandas.DataFrame): The feature matrix.\n",
    "        y (pandas.Series): The target variable.\n",
    "        p_value (float, optional): The significance level for feature selection. Defaults to 0.05.\n",
    "    Returns:\n",
    "        list: A list of selected features.\n",
    "    \"\"\"\n",
    "    features = list(X.columns)  # Get the list of all features\n",
    "    selected_features = []  # Initialize the list of selected features\n",
    "    best_aic = float('inf')  # Initialize the best AIC value\n",
    "\n",
    "    while features:\n",
    "        candidates = [\n",
    "            (sm.OLS(y, sm.add_constant(X[selected_features + [f]])).fit().bic, f) # # Calculate BIC for each candidate feature (can use the aic criterion)\n",
    "            for f in features\n",
    "            ]\n",
    "        candidates.sort()  # Sort candidates based on criterion\n",
    "        best_candidate_aic, best_candidate = candidates[0]  # Get the candidate with the lowest value\n",
    "\n",
    "        if best_candidate_aic < best_aic:\n",
    "            print(f\"Adding feature {best_candidate} AIC/BIC {best_candidate_aic:.2f}\") # Print the added feature and its AIC/BIC\n",
    "            best_aic = best_candidate_aic  # Update the best AIC value\n",
    "            selected_features.append(best_candidate)  # Add the selected feature to the list\n",
    "            features.remove(best_candidate)  # Remove the selected feature from the candidate list\n",
    "        else:\n",
    "            break  # Stop if no further improvement in AIC/BIC\n",
    "    return selected_features  # Return the list of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cea10-f1a9-4475-b77e-8b4e745c23c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d6cea10-f1a9-4475-b77e-8b4e745c23c8",
    "outputId": "9a601d73-f2a9-4d8c-c8c5-486ac3a329c8"
   },
   "outputs": [],
   "source": [
    "# running the stepwise function\n",
    "selected_features = stepwise_selection(X_features, y)\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2ce73-6087-46bd-864f-aee53a1d9968",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ada2ce73-6087-46bd-864f-aee53a1d9968",
    "outputId": "9985a2e3-6592-470a-c9ad-fba57cd967d4"
   },
   "outputs": [],
   "source": [
    "# Fitting to the selected features (get the features from X0 dataframe)\n",
    "X2 = X0[selected_features + ['const']]  # Create a new feature matrix with selected features and constant term\n",
    "model2 = sm.OLS(y, X2).fit()  # Fit an OLS regression model using selected features\n",
    "print(model2.summary(alpha = 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da75d4-f9da-430c-b86d-4e0a6a4514b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "21da75d4-f9da-430c-b86d-4e0a6a4514b4",
    "outputId": "67396772-de96-433d-8079-ec7feb633d51"
   },
   "outputs": [],
   "source": [
    "# Drawing the sscatterplot y-y_predict\n",
    "y2_predict = model2.predict(X2)\n",
    "plot_scatter(y2_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc12a82-2f90-4143-a246-c7d721fc9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Box-Plot\n",
    "u_std_df['residuals_2'] = y-y2_predict  # Add the residuals to the unique explosives dataframe \n",
    "plot_residuals_by_class(u_std_df, residuals_col='residuals_2', group_col='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caaefa8-cd37-409d-bd65-6b996cb030a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "7caaefa8-cd37-409d-bd65-6b996cb030a0",
    "outputId": "5d59663b-62b8-4220-a2db-d728fee00465"
   },
   "outputs": [],
   "source": [
    "# Checking variance inflation factor to assess multicollinearity\n",
    "pd.Series([variance_inflation_factor(X2.values, i) for i in range(X2.shape[1])], index=X2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0fbbac-e288-4129-ba6d-1fe811aadaa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b0fbbac-e288-4129-ba6d-1fe811aadaa2",
    "outputId": "749edf06-208e-4d0b-89c1-bee46d1df55d"
   },
   "outputs": [],
   "source": [
    "# Removing some features and Fitting the new model\n",
    "X3=X2.drop(['NOO'], axis=1)\n",
    "model3 = sm.OLS(y, X3).fit()\n",
    "print(model3.summary(alpha = 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963eca4-fad2-42b9-a09b-9185ff9dd01f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "f963eca4-fad2-42b9-a09b-9185ff9dd01f",
    "outputId": "a0368f02-a8fa-4597-f962-8d9f574e0536"
   },
   "outputs": [],
   "source": [
    "# Checking variance inflation factor to assess multicollinearity\n",
    "pd.Series([variance_inflation_factor(X3.values, i) for i in range(X3.shape[1])], index=X3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a46602-423e-4588-b6ad-4fe16b868dd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "66a46602-423e-4588-b6ad-4fe16b868dd2",
    "outputId": "4b40caf3-95e7-4ebd-8cb0-75273c0ab6af"
   },
   "outputs": [],
   "source": [
    "# Drawing the sscatterplot y-y_predict\n",
    "y3_predict = model3.predict(X3)\n",
    "plot_scatter(y3_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453ad7a-e255-4d88-b809-cdd18f103c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Box-Plot\n",
    "u_std_df['residuals_3'] = y-y3_predict  # Add the residuals to the unique explosives dataframe \n",
    "plot_residuals_by_class(u_std_df, residuals_col='residuals_3', group_col='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c865ee3-35e6-48d4-9de6-4666bb5f6970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----Checking the model with non-aggregated data from the standardized database\n",
    "std_df[target] = num_df[target] # Change the target to non-standardized value\n",
    "std_df['num_type'] =  num_df['num_type']  # Change the num_type to non-standardized value\n",
    "std_df['const'] = 1  # Add the model const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8ca93-09d2-4950-b009-aa1c5808dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the sscatterplot y-y_predict (data not aggregated)\n",
    "y3_predict_all = model3.predict(std_df[X3.columns])\n",
    "plot_scatter(y3_predict_all, std_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be3362-c480-438b-a2af-1f45dd7249b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Box-Plot\n",
    "std_df['all_residuals_3'] = std_df[target] - y3_predict_all  # Add the residuals to the unique explosives dataframe \n",
    "plot_residuals_by_class(std_df, residuals_col='all_residuals_3', group_col='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c80270-65e2-4ebb-8203-e1cd5179c454",
   "metadata": {
    "id": "01c80270-65e2-4ebb-8203-e1cd5179c454"
   },
   "source": [
    "## More Diagnostics Plots\n",
    "\n",
    "The following code cell is from: https://www.statsmodels.org/dev/examples/notebooks/generated/linear_regression_diagnostics_plots.html\n",
    "(Authors: Prajwal Kafle and Matt Spinelli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0c0b6-985e-456e-9451-1a00e01fb576",
   "metadata": {
    "id": "b3c0c0b6-985e-456e-9451-1a00e01fb576"
   },
   "outputs": [],
   "source": [
    "# ----base code\n",
    "import statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "#import numpy as np\n",
    "#import seaborn as sns\n",
    "from statsmodels.tools.tools import maybe_unwrap_results\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#import matplotlib.pyplot as plt\n",
    "from typing import Type\n",
    "\n",
    "style_talk = 'seaborn-talk'    #refer to plt.style.available\n",
    "\n",
    "class LinearRegDiagnostic():\n",
    "    \"\"\"\n",
    "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
    "    Mainly,\n",
    "        a. non-linearity of data\n",
    "        b. Correlation of error terms\n",
    "        c. non-constant variance\n",
    "        d. outliers\n",
    "        e. high-leverage points\n",
    "        f. collinearity\n",
    "\n",
    "    Authors:\n",
    "        Prajwal Kafle (p33ajkafle@gmail.com, where 3 = r)\n",
    "        Does not come with any sort of warranty.\n",
    "        Please test the code one your end before using.\n",
    "\n",
    "        Matt Spinelli (m3spinelli@gmail.com, where 3 = r)\n",
    "        (1) Fixed incorrect annotation of the top most extreme residuals in\n",
    "            the Residuals vs Fitted and, especially, the Normal Q-Q plots.\n",
    "        (2) Changed Residuals vs Leverage plot to match closer the y-axis\n",
    "            range shown in the equivalent plot in the R package ggfortify.\n",
    "        (3) Added horizontal line at y=0 in Residuals vs Leverage plot to\n",
    "            match the plots in R package ggfortify and base R.\n",
    "        (4) Added option for placing a vertical guideline on the Residuals\n",
    "            vs Leverage plot using the rule of thumb of h = 2p/n to denote\n",
    "            high leverage (high_leverage_threshold=True).\n",
    "        (5) Added two more ways to compute the Cook's Distance (D) threshold:\n",
    "            * 'baseR': D > 1 and D > 0.5 (default)\n",
    "            * 'convention': D > 4/n\n",
    "            * 'dof': D > 4 / (n - k - 1)\n",
    "        (6) Fixed class name to conform to Pascal casing convention\n",
    "        (7) Fixed Residuals vs Leverage legend to work with loc='best'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper]) -> None:\n",
    "        \"\"\"\n",
    "        For a linear regression model, generates following diagnostic plots:\n",
    "\n",
    "        a. residual\n",
    "        b. qq\n",
    "        c. scale location and\n",
    "        d. leverage\n",
    "\n",
    "        and a table\n",
    "\n",
    "        e. vif\n",
    "\n",
    "        Args:\n",
    "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]):\n",
    "                must be instance of statsmodels.regression.linear_model object\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if instance does not belong to above object\n",
    "\n",
    "        Example:\n",
    "        >>> import numpy as np\n",
    "        >>> import pandas as pd\n",
    "        >>> import statsmodels.formula.api as smf\n",
    "        >>> x = np.linspace(-np.pi, np.pi, 100)\n",
    "        >>> y = 3*x + 8 + np.random.normal(0,1, 100)\n",
    "        >>> df = pd.DataFrame({'x':x, 'y':y})\n",
    "        >>> res = smf.ols(formula= \"y ~ x\", data=df).fit()\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls(plot_context=\"seaborn-v0_8-paper\")\n",
    "\n",
    "        In case you do not need all plots you can also independently make an individual plot/table\n",
    "        in following ways\n",
    "\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls.residual_plot()\n",
    "        >>> cls.qq_plot()\n",
    "        >>> cls.scale_location_plot()\n",
    "        >>> cls.leverage_plot()\n",
    "        >>> cls.vif_table()\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(results, statsmodels.regression.linear_model.RegressionResultsWrapper) is False:\n",
    "            raise TypeError(\"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\")\n",
    "\n",
    "        self.results = maybe_unwrap_results(results)\n",
    "\n",
    "        self.y_true = self.results.model.endog\n",
    "        self.y_predict = self.results.fittedvalues\n",
    "        self.xvar = self.results.model.exog\n",
    "        self.xvar_names = self.results.model.exog_names\n",
    "\n",
    "        self.residual = np.array(self.results.resid)\n",
    "        influence = self.results.get_influence()\n",
    "        self.residual_norm = influence.resid_studentized_internal\n",
    "        self.leverage = influence.hat_matrix_diag\n",
    "        self.cooks_distance = influence.cooks_distance[0]\n",
    "        self.nparams = len(self.results.params)\n",
    "        self.nresids = len(self.residual_norm)\n",
    "\n",
    "    def __call__(self, plot_context='seaborn-v0_8-paper', **kwargs):\n",
    "        # print(plt.style.available)\n",
    "        # GH#9157\n",
    "        if plot_context not in plt.style.available:\n",
    "            plot_context = 'default'\n",
    "        with plt.style.context(plot_context):\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "            self.residual_plot(ax=ax[0,0])\n",
    "            self.qq_plot(ax=ax[0,1])\n",
    "            self.scale_location_plot(ax=ax[1,0])\n",
    "            self.leverage_plot(\n",
    "                ax=ax[1,1],\n",
    "                high_leverage_threshold = kwargs.get('high_leverage_threshold'),\n",
    "                cooks_threshold = kwargs.get('cooks_threshold'))\n",
    "            plt.show()\n",
    "\n",
    "        return self.vif_table(), fig, ax,\n",
    "\n",
    "    def residual_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Fitted Plot\n",
    "\n",
    "        Graphical tool to identify non-linearity.\n",
    "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        sns.residplot(\n",
    "            x=self.y_predict,\n",
    "            y=self.residual,\n",
    "            lowess=True,\n",
    "            scatter_kws={'alpha': 0.5},\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        residual_abs = np.abs(self.residual)\n",
    "        abs_resid = np.flip(np.argsort(residual_abs), 0)\n",
    "        abs_resid_top_3 = abs_resid[:3]\n",
    "        for i in abs_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.y_predict[i], self.residual[i]),\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Residuals vs Fitted', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel('Residuals')\n",
    "        return ax\n",
    "\n",
    "    def qq_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Standarized Residual vs Theoretical Quantile plot\n",
    "\n",
    "        Used to visually check if residuals are normally distributed.\n",
    "        Points spread along the diagonal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        QQ = ProbPlot(self.residual_norm)\n",
    "        fig = QQ.qqplot(line='45', alpha=0.5, lw=1, ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
    "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "        for i, x, y in self.__qq_top_resid(QQ.theoretical_quantiles, abs_norm_resid_top_3):\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(x, y),\n",
    "                ha='right',\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Normal Q-Q', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Theoretical Quantiles')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        return ax\n",
    "\n",
    "    def scale_location_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Sqrt(Standarized Residual) vs Fitted values plot\n",
    "\n",
    "        Used to check homoscedasticity of the residuals.\n",
    "        Horizontal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        residual_norm_abs_sqrt = np.sqrt(np.abs(self.residual_norm))\n",
    "\n",
    "        ax.scatter(self.y_predict, residual_norm_abs_sqrt, alpha=0.5);\n",
    "        sns.regplot(\n",
    "            x=self.y_predict,\n",
    "            y=residual_norm_abs_sqrt,\n",
    "            scatter=False, ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_sq_norm_resid = np.flip(np.argsort(residual_norm_abs_sqrt), 0)\n",
    "        abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "        for i in abs_sq_norm_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.y_predict[i], residual_norm_abs_sqrt[i]),\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Scale-Location', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel(r'$\\sqrt{|\\mathrm{Standardized\\ Residuals}|}$');\n",
    "        return ax\n",
    "\n",
    "    def leverage_plot(self, ax=None, high_leverage_threshold=False, cooks_threshold='baseR'):\n",
    "        \"\"\"\n",
    "        Residual vs Leverage plot\n",
    "\n",
    "        Points falling outside Cook's distance curves are considered observation that can sway the fit\n",
    "        aka are influential.\n",
    "        Good to have none outside the curves.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        ax.scatter(\n",
    "            self.leverage,\n",
    "            self.residual_norm,\n",
    "            alpha=0.5);\n",
    "\n",
    "        sns.regplot(\n",
    "            x=self.leverage,\n",
    "            y=self.residual_norm,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        leverage_top_3 = np.flip(np.argsort(self.cooks_distance), 0)[:3]\n",
    "        for i in leverage_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.leverage[i], self.residual_norm[i]),\n",
    "                color = 'C3')\n",
    "\n",
    "        factors = []\n",
    "        if cooks_threshold == 'baseR' or cooks_threshold is None:\n",
    "            factors = [1, 0.5]\n",
    "        elif cooks_threshold == 'convention':\n",
    "            factors = [4/self.nresids]\n",
    "        elif cooks_threshold == 'dof':\n",
    "            factors = [4/ (self.nresids - self.nparams)]\n",
    "        else:\n",
    "            raise ValueError(\"threshold_method must be one of the following: 'convention', 'dof', or 'baseR' (default)\")\n",
    "        for i, factor in enumerate(factors):\n",
    "            label = \"Cook's distance\" if i == 0 else None\n",
    "            xtemp, ytemp = self.__cooks_dist_line(factor)\n",
    "            ax.plot(xtemp, ytemp, label=label, lw=1.25, ls='--', color='red')\n",
    "            ax.plot(xtemp, np.negative(ytemp), lw=1.25, ls='--', color='red')\n",
    "\n",
    "        if high_leverage_threshold:\n",
    "            high_leverage = 2 * self.nparams / self.nresids\n",
    "            if max(self.leverage) > high_leverage:\n",
    "                ax.axvline(high_leverage, label='High leverage', ls='-.', color='purple', lw=1)\n",
    "\n",
    "        ax.axhline(0, ls='dotted', color='black', lw=1.25)\n",
    "        ax.set_xlim(0, max(self.leverage)+0.01)\n",
    "        ax.set_ylim(min(self.residual_norm)-0.1, max(self.residual_norm)+0.1)\n",
    "        ax.set_title('Residuals vs Leverage', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Leverage')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        plt.legend(loc='best')\n",
    "        return ax\n",
    "\n",
    "    def vif_table(self):\n",
    "        \"\"\"\n",
    "        VIF table\n",
    "\n",
    "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
    "        VIF > 5 for a variable indicates that it is highly collinear with the\n",
    "        other input variables.\n",
    "        \"\"\"\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"Features\"] = self.xvar_names\n",
    "        vif_df[\"VIF Factor\"] = [variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])]\n",
    "\n",
    "        return (vif_df\n",
    "                .sort_values(\"VIF Factor\")\n",
    "                .round(2))\n",
    "\n",
    "\n",
    "    def __cooks_dist_line(self, factor):\n",
    "        \"\"\"\n",
    "        Helper function for plotting Cook's distance curves\n",
    "        \"\"\"\n",
    "        p = self.nparams\n",
    "        formula = lambda x: np.sqrt((factor * p * (1 - x)) / x)\n",
    "        x = np.linspace(0.001, max(self.leverage), 50)\n",
    "        y = formula(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __qq_top_resid(self, quantiles, top_residual_indices):\n",
    "        \"\"\"\n",
    "        Helper generator function yielding the index and coordinates\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        quant_index = 0\n",
    "        previous_is_negative = None\n",
    "        for resid_index in top_residual_indices:\n",
    "            y = self.residual_norm[resid_index]\n",
    "            is_negative = y < 0\n",
    "            if previous_is_negative == None or previous_is_negative == is_negative:\n",
    "                offset += 1\n",
    "            else:\n",
    "                quant_index -= offset\n",
    "            x = quantiles[quant_index] if is_negative else np.flip(quantiles, 0)[quant_index]\n",
    "            quant_index += 1\n",
    "            previous_is_negative = is_negative\n",
    "            yield resid_index, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f5a6a-d687-4eaf-90d4-7b6fda666f13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "302f5a6a-d687-4eaf-90d4-7b6fda666f13",
    "outputId": "7540d3ba-bad2-47d4-9660-5b014ce6d36d"
   },
   "outputs": [],
   "source": [
    "# Generating diagnostic plots\n",
    "cls = LinearRegDiagnostic(model3)\n",
    "# Residual vs Fitted values to identify non-linearity\n",
    "cls.residual_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152fe2ff-6ef3-440c-a32b-aca5dd2ea98b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "152fe2ff-6ef3-440c-a32b-aca5dd2ea98b",
    "outputId": "4cc461de-9d0e-49b8-ba09-b171d1cca3c5"
   },
   "outputs": [],
   "source": [
    "# Standarized Residual vs Theoretical Quantile to check if residuals are normally distributed\n",
    "cls.qq_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bed17-4e2d-4591-9aea-1621d63fbced",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "fd9bed17-4e2d-4591-9aea-1621d63fbced",
    "outputId": "c48f47f2-3a32-4cbe-df4e-6202b9b50fd1"
   },
   "outputs": [],
   "source": [
    "# ---Sqrt(Standarized Residual) vs Fitted values to check homoscedasticity of the residuals\n",
    "cls.scale_location_plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1179bed-3eba-4491-b8d0-0bfda07c7fb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "d1179bed-3eba-4491-b8d0-0bfda07c7fb3",
    "outputId": "3dd43c20-8c3d-4062-bae3-4f21cc9826a9"
   },
   "outputs": [],
   "source": [
    "# ----Residual vs Leverage to check observations that can sway the fit aka are influential (points falling outside the Cookâ€™s distance curves)\n",
    "cls.leverage_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcc4c7-d1a9-4639-8489-40ecb017d92f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "07bcc4c7-d1a9-4639-8489-40ecb017d92f",
    "outputId": "2afa1fd0-a27a-4002-93e3-a04581449cf3"
   },
   "outputs": [],
   "source": [
    "# ----Cookâ€™s distance curves can be drawn using other conventions (see above the code)\n",
    "cls.leverage_plot(high_leverage_threshold=True, cooks_threshold='dof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cac72f-836c-423d-8e85-3678730c2f3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "20cac72f-836c-423d-8e85-3678730c2f3b",
    "outputId": "679019c8-3f55-4418-ae5c-4003681439f0"
   },
   "outputs": [],
   "source": [
    "# ----Checking variance inflation factor to assess multicollinearity\n",
    "pd.Series([variance_inflation_factor(X3.values, i) for i in range(X3.shape[1])], index=X3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c0635-5e40-40df-bbfc-a1fdb2dc7fd0",
   "metadata": {
    "id": "d59c0635-5e40-40df-bbfc-a1fdb2dc7fd0"
   },
   "source": [
    "## Other packages: r-car, pingouin...\n",
    "Should you wish to experiment with other statistical packages, you are at liberty to do so in order to tailor the utilities to your needs. Example:\n",
    "\n",
    "conda install -c conda-forge pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31149812-f3a6-4e1b-b934-69670ccac4da",
   "metadata": {
    "id": "31149812-f3a6-4e1b-b934-69670ccac4da"
   },
   "outputs": [],
   "source": [
    "# ----Load the package\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SNHT9aZuO_vV",
   "metadata": {
    "id": "SNHT9aZuO_vV"
   },
   "outputs": [],
   "source": [
    "# pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d175f-cee9-4ea0-995b-367eb0d31ae6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a0d175f-cee9-4ea0-995b-367eb0d31ae6",
    "outputId": "2b6b6e55-0626-48fd-acb4-c0028a19e3bf"
   },
   "outputs": [],
   "source": [
    "# ----Pearsonâ€™s correlation\n",
    "print('Pearson correlation')\n",
    "p_corr = pg.corr(X_features['q_per_g'].values, y.values)\n",
    "print(p_corr)\n",
    "print('...............................................')\n",
    "print('robust correlation')\n",
    "r_corr = pg.corr(X_features['q_per_g'].values, y.values, method=\"bicor\")\n",
    "print(r_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0a772-aae9-4d67-9011-cea441f93ef0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "0cb0a772-aae9-4d67-9011-cea441f93ef0",
    "outputId": "e51e3a97-d36f-4440-edc1-d5f404d0625c"
   },
   "outputs": [],
   "source": [
    "# ----Testing the normality\n",
    "# First get the residuals fro them last model\n",
    "residuals3 = pd.DataFrame(y - model3.predict(X3))\n",
    "# Numerical\n",
    "print(pg.normality(residuals3, method='shapiro', alpha=0.05))\n",
    "# Graphical with confidence curves\n",
    "ax = pg.qqplot(residuals3, dist='norm', confidence=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc9ab3-75bf-4edf-9770-1079c86ea650",
   "metadata": {
    "id": "16fc9ab3-75bf-4edf-9770-1079c86ea650"
   },
   "source": [
    "# .....................................................................................................................<br>\n",
    "## .....................................................................................................................<br>\n",
    "### .....................................................................................................................<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44daaba2-0621-411b-939f-5a54acdb18a2",
   "metadata": {
    "id": "44daaba2-0621-411b-939f-5a54acdb18a2"
   },
   "source": [
    "# Linear regression using scikit_learn and cross-validation (cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe868e26-fcba-4f92-942a-69a3dfa52b58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe868e26-fcba-4f92-942a-69a3dfa52b58",
    "outputId": "1588ecb4-163b-4775-b3bd-7f3eb80e165b"
   },
   "outputs": [],
   "source": [
    "# ----Load the necessary libraries\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, LassoLarsIC\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Instance to LinearRegression class\n",
    "clf = LinearRegression()\n",
    "\n",
    "# We are going to start the examples with recursive feature elimination method to select the important feaures\n",
    "# Initial parameters\n",
    "min_features = 2  # Minimum number of features to consider\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=111166) # Parameters of cv\n",
    "# Working with Train/test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=111166)\n",
    "\n",
    "# Using the method RFECV for recursive feature elimination by cross-validation (rmse criteria)\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_root_mean_squared_error\", # you can change the criteria for scoring: \"neg_median_absolute_error\" \"r2\"\n",
    "    min_features_to_select=min_features,\n",
    "    n_jobs=1,\n",
    ")\n",
    "rfecv.fit(X_train, y_train)\n",
    "# Use dir(rfecv) for seeing the avaliable methods\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "print(f'The selected features are: {rfecv.get_feature_names_out()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc8797-2c0a-4431-b79b-21cf7dc4d3e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "3fcc8797-2c0a-4431-b79b-21cf7dc4d3e0",
    "outputId": "4c7e6aaa-99d1-4462-b5f7-fe98ed79c1df"
   },
   "outputs": [],
   "source": [
    "# ----Checking and plotting results\n",
    "try:\n",
    "    cv_results = pd.DataFrame.from_dict(rfecv.cv_results_)  # This conversion doesnt work on all versions \n",
    "    x_=cv_results[\"n_features\"]\n",
    "    y_=cv_results[\"mean_test_score\"]\n",
    "    yerr=cv_results[\"std_test_score\"]\n",
    "except Exception as e:\n",
    "    x_=rfecv.cv_results_[\"n_features\"]\n",
    "    y_=rfecv.cv_results_[\"mean_test_score\"]\n",
    "    yerr=rfecv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test score\")\n",
    "plt.errorbar(\n",
    "    x=x_,\n",
    "    y=y_,\n",
    "    yerr=yerr,\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\n\")\n",
    "plt.show()\n",
    "# rfecv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33b991-4287-4251-8516-3c8550b9def2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db33b991-4287-4251-8516-3c8550b9def2",
    "outputId": "40d2c558-4d4e-4668-c880-e17237de1425"
   },
   "outputs": [],
   "source": [
    "# ----Print Features selected\n",
    "print(rfecv.ranking_)\n",
    "selected_features = X_features.columns[rfecv.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b9493-0f45-47b9-bede-3da5a2f57dd6",
   "metadata": {
    "id": "098b9493-0f45-47b9-bede-3da5a2f57dd6"
   },
   "source": [
    "# Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a7055-f6c0-4b65-b86c-101e5809cf03",
   "metadata": {
    "id": "920a7055-f6c0-4b65-b86c-101e5809cf03"
   },
   "outputs": [],
   "source": [
    "# ----Funtion to calculate rmse from cv_test (train) and test: Linear Regression\n",
    "def rmse_regression(features, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    \"\"\"\n",
    "    Calculates and prints the RMSE for linear regression using given features.\n",
    "\n",
    "    Args:\n",
    "        features (list): A list of feature names to use in the regression.\n",
    "        X_train (pandas.DataFrame, optional): The training feature matrix. Defaults to the global 'X_train' variable.\n",
    "        y_train (pandas.Series, optional): The training target variable. Defaults to the global 'y_train' variable.\n",
    "        X_test (pandas.DataFrame, optional): The testing feature matrix. Defaults to the global 'X_test' variable.\n",
    "        y_test (pandas.Series, optional): The testing target variable. Defaults to the global 'y_test' variable.\n",
    "    \"\"\"\n",
    "    for i in features:\n",
    "        X_train = X_train[features]  # Select features for training\n",
    "        X_test = X_test[features]  # Select features for testing\n",
    "        lin_reg = LinearRegression().fit(X_train, y_train)  # Fit a linear regression model\n",
    "        # Calculate rmse on training and test data using cross-validation\n",
    "        lin_score_train = -1 * cross_val_score(lin_reg, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "        lin_score_test = root_mean_squared_error(y_test, lin_reg.predict(X_test))\n",
    "    print(f' cv_test_rmse and test_rmse for {features}: {lin_score_train:.2f}, {lin_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b546e-ce1c-476d-b54a-90f953a961ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e82b546e-ce1c-476d-b54a-90f953a961ef",
    "outputId": "6e880259-6af0-4679-fb91-6c72508c4be4"
   },
   "outputs": [],
   "source": [
    "# ----The results of linear regression\n",
    "rmse_regression(selected_features)  # Calculate and print RMSE for selected features\n",
    "rmse_regression(X3.columns.drop('const'))  # Calculate and print RMSE for features in X3 (you have to drop the 'const')\n",
    "rmse_regression(X2.columns.drop('const'))  # Calculate and print RMSE for features in X2 (you have to drop the 'const')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3086c3-68fa-4651-8e2e-778018d2378c",
   "metadata": {
    "id": "3e3086c3-68fa-4651-8e2e-778018d2378c"
   },
   "source": [
    "## You can try other regression techniques...\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ridge_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fedd2-3195-42c1-841c-b3f6ba3ca3ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a06fedd2-3195-42c1-841c-b3f6ba3ca3ad",
    "outputId": "71f68dd8-b293-4059-d0ec-fa7e4526882f"
   },
   "outputs": [],
   "source": [
    "# ----rmse train and test: Lasso Regression\n",
    "lasso_reg = LassoCV(max_iter=2000, random_state=111166, tol=0.012).fit(X_train, y_train) # Note that max_iter and tol values are set manually in this example\n",
    "lasso_score_train = -1 * cross_val_score(lasso_reg, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "lasso_score_test = root_mean_squared_error(y_test, lasso_reg.predict(X_test))\n",
    "print(f'rmse cv_test and rmse test with Lasso {lasso_score_train:.2f}, {lasso_score_test:.2f}')\n",
    "print(lasso_reg.coef_)\n",
    "features_arg = X_train.columns[np.abs(lasso_reg.coef_)>0]\n",
    "print(f'the selected features by Lasso are {[i for i in features_arg]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e51e3-f0b3-4458-a2e6-c374bbac1973",
   "metadata": {
    "id": "f95e51e3-f0b3-4458-a2e6-c374bbac1973"
   },
   "outputs": [],
   "source": [
    "#  ----Selecting Lasso model via an information criterion (selection of the alpha parameter value using the aic criterion)\n",
    "lasso_lars_aic = LassoLarsIC(criterion=\"aic\").fit(X_train, y_train)\n",
    "# saving some results in a dataframe\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"alphas\": lasso_lars_aic.alphas_,\n",
    "        \"AIC criterion\": lasso_lars_aic.criterion_,\n",
    "    }\n",
    ").set_index(\"alphas\")\n",
    "alpha_aic = lasso_lars_aic.alpha_\n",
    "# run: dir(lasso_lars_aic) to see the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bfde6-f19e-494a-808e-3c80a853090b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "437bfde6-f19e-494a-808e-3c80a853090b",
    "outputId": "d8e63cd4-5277-4ae3-a4fc-4644048a98aa"
   },
   "outputs": [],
   "source": [
    "# ----Printing the aic vs alpha\n",
    "def highlight_min(x):\n",
    "    \"\"\"\n",
    "    Highlights the minimum value in a Series.\n",
    "    Args:\n",
    "        x (pandas.Series): The input Series.\n",
    "    Returns:\n",
    "        list: A list of styles for each value in the Series.\n",
    "    \"\"\"\n",
    "    x_min = x.min()\n",
    "    return [\"font-weight: bold\" if v == x_min else \"\" for v in x]\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49318673-15ac-4fa6-ae69-0ca76e4dc6f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "49318673-15ac-4fa6-ae69-0ca76e4dc6f4",
    "outputId": "ab9c4b0e-7fa5-4f27-b997-f6781e1773d2"
   },
   "outputs": [],
   "source": [
    "# ----Graphic results\n",
    "ax = results.plot()\n",
    "ax.vlines(\n",
    "    alpha_aic,\n",
    "    results[\"AIC criterion\"].min(),\n",
    "    results[\"AIC criterion\"].max(),\n",
    "    label=\"alpha: AIC estimate\",\n",
    "    linestyles=\"--\",\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "ax.set_xlabel(r\"$\\alpha$\")\n",
    "ax.set_ylabel(\"criterion\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend()\n",
    "_ = ax.set_title(\n",
    "    f\"Information-criterion for model selection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8c580-7cc1-46b3-85d7-b8b50f249630",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02d8c580-7cc1-46b3-85d7-b8b50f249630",
    "outputId": "11aa9d88-95a0-4749-c39d-1d331b594b23"
   },
   "outputs": [],
   "source": [
    "# ----Selected features by Lasso\n",
    "features_Lasso_aic = X_train.columns[np.abs(lasso_lars_aic.coef_)>0]\n",
    "print(f'the selected features by Lasso with the aic criterion are: {[i for i in features_Lasso_aic]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00938f41-cc00-4f4e-8315-e1a4ffa5fba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00938f41-cc00-4f4e-8315-e1a4ffa5fba9",
    "outputId": "38c9b2c1-8125-45ae-9fce-fff55cddff7f"
   },
   "outputs": [],
   "source": [
    "# ----The results of linear regression with the Lasso_aic parameters\n",
    "rmse_regression(features_Lasso_aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac518f74-581d-4994-823c-4af219b63d06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac518f74-581d-4994-823c-4af219b63d06",
    "outputId": "b0a531a7-3b44-470b-feb4-e07b726a6c6a"
   },
   "outputs": [],
   "source": [
    "# ----rmse train and test: Ridge Regression\n",
    "ridge_reg = RidgeCV().fit(X_train, y_train)\n",
    "ridge_score_train = -1 * cross_val_score(ridge_reg, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "ridge_score_test = root_mean_squared_error(y_test, ridge_reg.predict(X_test))\n",
    "print(f'rmse cv_test and rmse test with Ridge {ridge_score_train:.2f}, {ridge_score_test:.2f}')\n",
    "print(ridge_reg.coef_)\n",
    "threshold_weight = 0.01\n",
    "features_Ridge = X_train.columns[np.abs(ridge_reg.coef_)>threshold_weight]\n",
    "print(f'the selected features by Ridge are {[i for i in features_Ridge]}')\n",
    "print('.................................................................')\n",
    "print('.................................................................')\n",
    "print('.................................................................')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60999a-1084-4592-b515-9042d24bf592",
   "metadata": {
    "id": "cd60999a-1084-4592-b515-9042d24bf592"
   },
   "source": [
    "## Principal Component Regression (PCR) and Cross-Validation\n",
    "https://nirpyresearch.com/principal-component-regression-python/<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html<br>\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77507de-67f7-4725-a58d-ea080abd8bec",
   "metadata": {
    "id": "d77507de-67f7-4725-a58d-ea080abd8bec"
   },
   "outputs": [],
   "source": [
    "# ----Trying PCA analysis for regression of principal components\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_not_intercept, y, test_size=0.2, random_state=111166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f526b-7f2f-49ac-9609-7eb933a841b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "509f526b-7f2f-49ac-9609-7eb933a841b2",
    "outputId": "b80f95a7-3035-4139-c498-57e3642271ee"
   },
   "outputs": [],
   "source": [
    "# ----Calculate the principal components\n",
    "pca = PCA() # default number of components = min(n_samples, n_features)\n",
    "X_pc = pca.fit_transform(X_features)\n",
    "print(X_pc)\n",
    "print(X_pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6a1a0-2d7c-4280-a7ab-b712550936c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "1cc6a1a0-2d7c-4280-a7ab-b712550936c3",
    "outputId": "fd7fbd57-96a0-4b84-e056-83faf9ef4fb7"
   },
   "outputs": [],
   "source": [
    "# ----Heatmap for checking no correlation betwen principal components\n",
    "X_pc_df = pd.DataFrame(X_pc, columns=[f'PC{i}' for i in range(0, len(X_features.columns))])\n",
    "pca_correlation_matrix = X_pc_df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pca_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('PCs Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4413a10-37c5-42fb-9e51-54344c4c74ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4413a10-37c5-42fb-9e51-54344c4c74ba",
    "outputId": "3045d8cc-9ca3-4e08-9f61-dd8d9ded4086"
   },
   "outputs": [],
   "source": [
    "# ----Showing features weights of each principal component\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=X_pc_df.columns, index=X_features.columns[:])\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f962163-403b-45c3-9d92-8151c38a79f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "3f962163-403b-45c3-9d92-8151c38a79f7",
    "outputId": "4f2bcd45-4bf8-4575-ecf8-82b5c7fc95c5"
   },
   "outputs": [],
   "source": [
    "# ----Heatmap for the loadings (same information in a visual way)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(loadings, annot=True, cmap='coolwarm')\n",
    "plt.title('PCA Loadings Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53af04-2331-430e-95d3-1310e818f6a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed53af04-2331-430e-95d3-1310e818f6a5",
    "outputId": "1d6f3473-5a18-4227-f543-637afaa3866a"
   },
   "outputs": [],
   "source": [
    "# ----Checking the most important features for each principal component\n",
    "# Choose a threshold for which features are considerated important for each principal component\n",
    "threshold = 0.3\n",
    "\n",
    "# Find features with loadings above the threshold for each principal component\n",
    "important_features = {}\n",
    "for column in loadings.columns:\n",
    "    important_features[column] = loadings.index[loadings[column].abs() > threshold].tolist()\n",
    "\n",
    "# Show the important features for each principal component\n",
    "for pc, features in important_features.items():\n",
    "    print(f\"{pc}: {', '.join(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0ba96-cff4-4783-bd4d-7b89fb7e9778",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0f0ba96-cff4-4783-bd4d-7b89fb7e9778",
    "outputId": "4462f7fd-8b0b-4ccb-9ac9-eb14bb11ab8e"
   },
   "outputs": [],
   "source": [
    "# ----Explained variance of each principal component\n",
    "print([f\"{i:.1%}\" for i in pca.explained_variance_ratio_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143d27c-624e-4276-a180-50b3fdca064d",
   "metadata": {
    "id": "3143d27c-624e-4276-a180-50b3fdca064d"
   },
   "outputs": [],
   "source": [
    "# ----Working with Train/test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pc, y, test_size=0.2, random_state=111166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becc97d-b592-47e9-bb32-686869e5d5cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7becc97d-b592-47e9-bb32-686869e5d5cb",
    "outputId": "7bb6a86b-fc9e-4ae2-a6fd-8b5d5ceb7bfb"
   },
   "outputs": [],
   "source": [
    "# -----Calculate the r2 variation, using KFold, with the number of components used in the regression\n",
    "# Define cross-validation folds\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=111166)\n",
    "\n",
    "# Linear regression instance\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Store RMSE for each regression case\n",
    "rmse_store = []\n",
    "\n",
    "# Loop through principal components for linear regression\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    rmse_ = cross_val_score(lin_reg,\n",
    "                            X_train[:,:i], # Use first k principal components\n",
    "                            y_train,\n",
    "                            cv=cv,\n",
    "                            scoring='neg_root_mean_squared_error')\n",
    "    rmse_store.append(rmse_)\n",
    "rmse_mean = [np.mean(i) for i in rmse_store]\n",
    "rmse_std = [np.std(i) for i in rmse_store]\n",
    "print('Number of principal components:')\n",
    "print([i for i in range(1, X_train.shape[1]+1)])\n",
    "print('rmse_mean')\n",
    "print([f\"{i:.2f}\" for i in rmse_mean])\n",
    "print('rmse_std')\n",
    "print([f\"{i:.2f}\" for i in rmse_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b7ebc-c955-488a-aa89-937ce0432812",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "f34b7ebc-c955-488a-aa89-937ce0432812",
    "outputId": "ec04aa8b-73ab-4326-c067-1fa3969048b9"
   },
   "outputs": [],
   "source": [
    "# ----Looking for the best option\n",
    "plt.plot(rmse_mean, '-x')\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('rmse[test_from_cv]')\n",
    "plt.xticks(np.arange(X_train.shape[1]), np.arange(1, X_train.shape[1]+1))\n",
    "plt.axhline(y=np.max(rmse_mean), color='r', linestyle='-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f3e4c-6c6b-42cf-988e-3ccda43bd111",
   "metadata": {
    "id": "941f3e4c-6c6b-42cf-988e-3ccda43bd111"
   },
   "outputs": [],
   "source": [
    "# ----Another method to calculate the r2 and rmse variation, using KFold, with the number of components used in the regression\n",
    "# Define cross-validation folds\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=111166)\n",
    "\n",
    "# Linear regression instance\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Store RMSE for each regression case\n",
    "fit_meas = []\n",
    "\n",
    "# Loop through principal components for linear regression\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    measures = cross_validate(lin_reg,\n",
    "                                X_train[:,:i], # Use first k principal components\n",
    "                                y_train,\n",
    "                                cv=cv,\n",
    "                                scoring=('r2', 'neg_root_mean_squared_error'))\n",
    "    fit_meas.append(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1c4cc-0858-4153-80e9-1acd61e0611f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98c1c4cc-0858-4153-80e9-1acd61e0611f",
    "outputId": "b89365bc-be1a-498c-a8f1-8fd355304361"
   },
   "outputs": [],
   "source": [
    "# ----See the contents of cross_validate object\n",
    "print([i for i in fit_meas[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483de69-274c-402b-b16b-8388e40fb8e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6483de69-274c-402b-b16b-8388e40fb8e6",
    "outputId": "65ae2272-cebd-4ff3-ca81-f473dd52c4bf"
   },
   "outputs": [],
   "source": [
    "# ----Pass the data to dataframe\n",
    "fit_meas_df = pd.DataFrame(fit_meas)\n",
    "print('Dataframe 0 dimension = number of principal components: ', fit_meas_df.shape[0])\n",
    "print('r2[test]', [fit_meas_df['test_r2'][i].mean() for i in range(fit_meas_df.shape[0])])\n",
    "print('rmse[test]', [-1*fit_meas_df['test_neg_root_mean_squared_error'][i].mean() for i in range(fit_meas_df.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b9d49-f161-4427-a95d-73c241d14caf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "a60b9d49-f161-4427-a95d-73c241d14caf",
    "outputId": "6b01a73d-e96d-4287-a6d3-ace976bcfb14"
   },
   "outputs": [],
   "source": [
    "# ----Looking for the best option\n",
    "plt.plot([fit_meas_df['test_r2'][i].mean() for i in range(fit_meas_df.shape[0])], '-x')\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('r2[test_from_crosss_validation]')\n",
    "plt.xticks(np.arange(X_train.shape[1]), np.arange(1, X_train.shape[1]+1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6628e7c-3552-4134-94fd-9eed941379fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6628e7c-3552-4134-94fd-9eed941379fd",
    "outputId": "98fb893e-c6ec-424d-acc2-c9323d2ee362"
   },
   "outputs": [],
   "source": [
    "# ----Selecting the number of principal components\n",
    "pc_number = 5\n",
    "X_train = X_train[:,:pc_number]\n",
    "X_test = X_test[:,:pc_number]\n",
    "print(f' Selected {pc_number} components, X_train[0:5,:]')\n",
    "print(X_train[0:5,:])\n",
    "print(' ....................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f1db8-2b9c-47ed-a9e8-535de0aefdab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f6f1db8-2b9c-47ed-a9e8-535de0aefdab",
    "outputId": "f09ae680-05c5-4330-e747-643a88726f5f"
   },
   "outputs": [],
   "source": [
    "# ----rmse train and test: Linear Regression\n",
    "lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "lin_score_train = -1 * cross_val_score(lin_reg, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "lin_score_test = root_mean_squared_error(y_test, lin_reg.predict(X_test))\n",
    "print(f' cv_test_rmse and test_rmse: {lin_score_train:.2f}, {lin_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96141b6-7a82-4875-a30c-18fed591bfde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a96141b6-7a82-4875-a30c-18fed591bfde",
    "outputId": "1b8b562a-e73e-43d3-d465-1f09e0b54765"
   },
   "outputs": [],
   "source": [
    "# ----r2 score without cv (only pc_number components)\n",
    "print(f' train_r2 and test_r2 with {pc_number} components: {lin_reg.score(X_train, y_train):.2%}, {lin_reg.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05f51d-b42b-4d3f-a5ed-842d46acf1b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "9f05f51d-b42b-4d3f-a5ed-842d46acf1b7",
    "outputId": "84775467-bcbc-4a1b-9890-185f900ab6e2"
   },
   "outputs": [],
   "source": [
    "# ----Drawing the sscatterplot y-y_predict\n",
    "plot_scatter(lin_reg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843ad48-539d-46f1-9d5d-a87e4b55c5f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3843ad48-539d-46f1-9d5d-a87e4b55c5f9",
    "outputId": "950b36a0-1c39-4b8d-8b8d-4f4377f609b7"
   },
   "outputs": [],
   "source": [
    "# ----r2 using the r2_score function\n",
    "print(f'r2_train: {r2_score(y_train, lin_reg.predict(X_train)):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602bc69-1fed-4bc8-a316-0a8d7b2c0a01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1602bc69-1fed-4bc8-a316-0a8d7b2c0a01",
    "outputId": "0520f4f0-0112-48a9-ab34-eb4d414712d1"
   },
   "outputs": [],
   "source": [
    "# ----Linear regression using all components\n",
    "lin_reg_all = LinearRegression().fit(np.array(X_pc), y)\n",
    "y_predict =  lin_reg_all.predict(np.array(X_pc))\n",
    "print(f'r2_all_components_all_data {r2_score(y, y_predict):.2%}')\n",
    "print(f'the rmse with all data and components is: {root_mean_squared_error(y, lin_reg_all.predict(X_pc)): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc77066-9276-4220-a94a-8b7edb2be12f",
   "metadata": {
    "id": "ffc77066-9276-4220-a94a-8b7edb2be12f"
   },
   "source": [
    "## Partial Least Squares (PLS) regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0223160-590b-4744-bc0e-a36ee3811857",
   "metadata": {
    "id": "d0223160-590b-4744-bc0e-a36ee3811857"
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e76033-f323-436d-9156-cb67ce92b613",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46e76033-f323-436d-9156-cb67ce92b613",
    "outputId": "2e3ec948-1ca1-4e47-a809-4504487d9b57"
   },
   "outputs": [],
   "source": [
    "# ----As with PCA, you can use all the features or only the most correlated ones\n",
    "n_components = X_features.shape[1] # all the components in this example\n",
    "pls_all = PLSRegression(n_components=n_components)\n",
    "pls_all.fit(X_features, y) # PLS scale the features\n",
    "y_predict = pls_all.predict(X_features)\n",
    "print('number of components: ', n_components)\n",
    "print(f\"PLS r-squared including all data and components in the regression: {pls_all.score(X_features, y):.2%}\")\n",
    "print(f\"and the rmse is {np.sqrt(mean_squared_error(y, y_predict)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c242907-b38e-4848-9f03-9b9b929edd68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c242907-b38e-4848-9f03-9b9b929edd68",
    "outputId": "09623d5d-4f3c-43c4-d831-d7ae9f3848b5"
   },
   "outputs": [],
   "source": [
    "# ----Get the most important features: those with the largest absolute values of the coefficients of the regression (y = coefficients X + intercept)\n",
    "print('the features analysed are ', pls_all.feature_names_in_)\n",
    "print('the coefficients of the linear model are', pls_all.coef_, 'and the intercept is', pls_all.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec05b0-b877-4800-85f1-e2962ac8e071",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeec05b0-b877-4800-85f1-e2962ac8e071",
    "outputId": "d267236f-da30-4f27-ab87-db25ea5a4457"
   },
   "outputs": [],
   "source": [
    "# ----PLS regression with cross-validation: looking for the best number of components\n",
    "parameters = {'n_components': np.arange(1, X_features.shape[1],1)}\n",
    "pls = GridSearchCV(PLSRegression(), parameters, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "pls.fit(X_features, y)\n",
    "print('the best number of components is ', pls.best_estimator_)\n",
    "print(f'the best score (cv_test_rmse) is, {-1*pls.best_score_: .2f}')\n",
    "print(f'the features analysed are ', pls.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa622e6-4357-4edc-9606-60ac049e85f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fa622e6-4357-4edc-9606-60ac049e85f0",
    "outputId": "d93a7010-0153-4c0e-faa7-c8f27d28b628"
   },
   "outputs": [],
   "source": [
    "# ----Showing and checking results\n",
    "results = pls.cv_results_\n",
    "results = pd.DataFrame(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed50c98-6dd3-4075-9550-98051515d820",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "6ed50c98-6dd3-4075-9550-98051515d820",
    "outputId": "97e5d756-8444-4703-aa05-77492fe38d57"
   },
   "outputs": [],
   "source": [
    "# ----Looking for the best option\n",
    "plt.plot([-1*results['mean_test_score'][i] for i in range(results.shape[0])], '-x')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('rmse[test_from_cv]')\n",
    "plt.xticks(np.arange(results.shape[1]), np.arange(1, results.shape[1]+1))\n",
    "plt.axhline(y=-1*results['mean_test_score'].max(), color='r', linestyle='-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6bd95-0b87-4be8-b93b-6c1cf585b570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ab6bd95-0b87-4be8-b93b-6c1cf585b570",
    "outputId": "8a4cc46a-481d-43c4-926f-77868b22c625"
   },
   "outputs": [],
   "source": [
    "# ----Checking the r2 for the best estimator\n",
    "y_cv = cross_val_predict(pls.best_estimator_, X_features, y, cv=cv)\n",
    "rmse_pls, score_pls = np.sqrt(mean_squared_error(y, y_cv)), r2_score(y, y_cv)\n",
    "print(f'the cv_rmse is: {rmse_pls:.2f}, and the cv_r2 is {score_pls:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc4b12-eca4-42c8-b189-0b9a888ca856",
   "metadata": {
    "id": "42bc4b12-eca4-42c8-b189-0b9a888ca856"
   },
   "outputs": [],
   "source": [
    "# ----Funtion to calculate the best estimator by ssquential features/components elimination\n",
    "def variable_elimination_pls(X, y, feature_names, initial_n_components, cv=10):\n",
    "    \"\"\"\n",
    "    Performs sequential variable and component elimination,\n",
    "    storing all solutions in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Matrix of independent variables (n_samples, n_features).\n",
    "        y (numpy.ndarray): Vector of the dependent variable (n_samples,).\n",
    "        feature_names (list): List of feature names (length: n_features).\n",
    "        initial_n_components (int): Initial number of PLS components.\n",
    "        cv (int, optional): Number of folds for cross-validation. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the results of each iteration,\n",
    "                          with the following columns:\n",
    "                          - 'n_components': Number of PLS components.\n",
    "                          - 'variables_indices': Indices of the remaining variables.\n",
    "                          - 'variables_names': Names of the remaining variables.\n",
    "                          - 'score': Score (neg_root_mean_squared_error) of the iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the length of feature_names matches the number of columns in X\n",
    "    if len(feature_names) != X.shape[1]:\n",
    "        raise ValueError(\"The length of 'feature_names' must be equal to the number of columns in 'X'\")\n",
    "\n",
    "    current_n_components = initial_n_components\n",
    "    remaining_vars = list(range(X.shape[1]))\n",
    "    print(remaining_vars)\n",
    "    # List to store the results of each iteration\n",
    "    results = []\n",
    "\n",
    "    while len(remaining_vars) > 0:\n",
    "        X_subset = X[:, remaining_vars]\n",
    "        best_score = float('inf')  # Initialize with the worst possible score\n",
    "        best_n_components = 0\n",
    "\n",
    "        while current_n_components > 0:\n",
    "            pls = PLSRegression(n_components=current_n_components)\n",
    "            scores = cross_val_score(pls, X_subset, y, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "            mean_score = np.mean(scores)\n",
    "\n",
    "            # Store the results of this iteration in the list\n",
    "            results.append({\n",
    "                'n_features': X_subset.shape[1],\n",
    "                'n_components': current_n_components,\n",
    "                'variables_indices': [i for i in remaining_vars],\n",
    "                'variables_names': [feature_names[i] for i in remaining_vars],\n",
    "                'score': -1 * mean_score\n",
    "            })\n",
    "\n",
    "            # Update the best score and number of components\n",
    "            if mean_score < best_score:\n",
    "                best_score = mean_score\n",
    "                best_n_components = current_n_components\n",
    "\n",
    "            current_n_components -= 1\n",
    "\n",
    "        current_n_components = X_subset.shape[1] - 1\n",
    "        if len(remaining_vars) > 1:\n",
    "            pls = PLSRegression(n_components=best_n_components)  # Use the best n_components\n",
    "            pls.fit(X_subset, y)\n",
    "            coefficients = pls.coef_.flatten()\n",
    "            least_important_var_index = np.argmin(np.abs(coefficients))\n",
    "            del remaining_vars[least_important_var_index]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Create a DataFrame from the list of results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eeda1-a2b2-4856-9579-febb9dbab7ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c16eeda1-a2b2-4856-9579-febb9dbab7ca",
    "outputId": "ee7ec824-6d0d-4e52-8cbb-69a7e7f689e8"
   },
   "outputs": [],
   "source": [
    "# ----Getting the results of the features elimination\n",
    "df_results = variable_elimination_pls(X_features.values, y.values, X_features.columns, X_features.shape[1], cv=cv)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b1b6e-3935-4a68-adf7-66943f7cbdc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f64b1b6e-3935-4a68-adf7-66943f7cbdc8",
    "outputId": "f984e2ca-c2cc-4a08-ec1e-20bc2f7a9d6a"
   },
   "outputs": [],
   "source": [
    "# ----Show the result with the best score\n",
    "best_result_index = df_results['score'].idxmin()\n",
    "best_result = df_results.loc[best_result_index]\n",
    "print(\"\\nBest result:\")\n",
    "print(best_result.to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efc51a-3612-480c-b0f1-ae0454dda62d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32efc51a-3612-480c-b0f1-ae0454dda62d",
    "outputId": "ccc409f5-9548-425e-8330-ccbd5901c920"
   },
   "outputs": [],
   "source": [
    "# ----Checking anothers solutions\n",
    "bests_results = df_results.query('score<0.30 & n_features<4')  # Try with some values\n",
    "print(bests_results.to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b841c7f-7f88-4ca4-85a9-3944faa7a05b",
   "metadata": {
    "id": "3b841c7f-7f88-4ca4-85a9-3944faa7a05b"
   },
   "source": [
    "## Random Forest Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a2382-9a63-4e20-9876-21ed6a0760a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "fd0a2382-9a63-4e20-9876-21ed6a0760a3",
    "outputId": "de728c5d-7887-48a8-eeb8-53a5387f8975"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = X_features[['Oxy_Balance', 'Moment1', 'q_per_g', 'num_type']]  # Select features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111166)\n",
    "\n",
    "# Define the hyperparameter grid to search the optimal values\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 30, 50],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [4, 6, 8],\n",
    "    'min_samples_leaf': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=111166, oob_score=True)\n",
    "\n",
    "# Negative root mean squared error\n",
    "neg_rmse = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=cv, scoring=neg_rmse, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa8f27-d3b1-4cf3-836b-b8de17881c04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6fa8f27-d3b1-4cf3-836b-b8de17881c04",
    "outputId": "67d46185-a321-44a2-f5df-9bc0f3b2ada6"
   },
   "outputs": [],
   "source": [
    "# ----Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(f'the mean cross-validated score (rmse) of the best_estimator is {-1*grid_search.best_score_:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31386469-4f15-4221-93d0-355e95cc2e43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31386469-4f15-4221-93d0-355e95cc2e43",
    "outputId": "e38c24ca-f08c-4e2e-ae93-a8d552f2f8b6"
   },
   "outputs": [],
   "source": [
    "# ----Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_rf = r2_score(y_test, y_pred)\n",
    "y_pred_train = best_rf_model.predict(X_train)\n",
    "rmse_rf_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "# Print the results\n",
    "print(f'Best score (r2) train: {best_rf_model.score(X_train, y_train):.2%}')\n",
    "print(f\"R-squared (r2) test: {r2_rf:.2%}\")\n",
    "print(f\"Root Mean Squared Error (rmse) train : {rmse_rf_train:.2f}\")\n",
    "print(f\"Root Mean Squared Error (rmse) test: {rmse_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69d8e7-0896-43a6-9795-8d1369b89e33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c69d8e7-0896-43a6-9795-8d1369b89e33",
    "outputId": "370801ad-b512-4277-f8e1-f3b98679f434"
   },
   "outputs": [],
   "source": [
    "# ----Check results\n",
    "rf_results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9235c79-11cb-40a9-90b7-abac955b1f19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9235c79-11cb-40a9-90b7-abac955b1f19",
    "outputId": "5cfa0eea-8fd8-4280-d042-ab60ca23d404"
   },
   "outputs": [],
   "source": [
    "# ----You can choose yours best parameters\n",
    "my_best = 10\n",
    "good_rf_params = grid_search.cv_results_['params'][my_best]\n",
    "print(good_rf_params)\n",
    "rf_model.set_params(**good_rf_params)\n",
    "my_best_rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df49210-c394-430a-842d-960254c13efb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "5df49210-c394-430a-842d-960254c13efb",
    "outputId": "5b807cf3-eb74-498b-d7e5-a613a59fe347"
   },
   "outputs": [],
   "source": [
    "# Display scatterplot of the prediction\n",
    "y_pred = my_best_rf_model.predict(X_test)\n",
    "# Drawing the sscatterplot y-y_predict\n",
    "plot_scatter(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c1d0a-cfbf-4ae2-a09e-af73cf7352fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be1c1d0a-cfbf-4ae2-a09e-af73cf7352fb",
    "outputId": "39b38445-48df-4b9a-ea35-3a27a29e7fcc"
   },
   "outputs": [],
   "source": [
    "# OOB score (Out-of-Bag score)\n",
    "if hasattr(my_best_rf_model, 'oob_score_') and my_best_rf_model.oob_score_:\n",
    "    print(f'r2 OOB (Out-of-Bag): {my_best_rf_model.oob_score_:.2f}')\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'the test_rsme is {np.sqrt(mse):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034e5e0-9aa3-4952-870e-3262541abdb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "d034e5e0-9aa3-4952-870e-3262541abdb0",
    "outputId": "a94fac16-ea63-4dcf-fa22-1b4f9a344119"
   },
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "importances = my_best_rf_model.feature_importances_\n",
    "features = X.columns\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b918c5-efe5-4d93-8192-c20b61d68571",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "f7b918c5-efe5-4d93-8192-c20b61d68571",
    "outputId": "9fd8e75f-115f-48ae-be6b-7bd1bec9c078"
   },
   "outputs": [],
   "source": [
    "# Plot permutation importances\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Plot the permutation importance\n",
    "result = permutation_importance(\n",
    "    my_best_rf_model, X_test, y_test, n_repeats=50, random_state=111162, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925d468-cfc4-4730-a841-9bbef821fe24",
   "metadata": {},
   "source": [
    "# Model Output Explainability: SHAP\n",
    "https://shap.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68517d-3a87-4d01-8e72-38c664cc2be5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "6d68517d-3a87-4d01-8e72-38c664cc2be5",
    "outputId": "c2b465a4-a5ea-4b2e-faed-c858533184cc"
   },
   "outputs": [],
   "source": [
    "# ---- Explain the model's predictions using SHAP\n",
    "import shap\n",
    "explainer = shap.Explainer(my_best_rf_model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# Visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b81c5-95d3-4669-9ff7-4ed708a437c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "f80b81c5-95d3-4669-9ff7-4ed708a437c7",
    "outputId": "f0ef62a5-fea7-469a-876f-8ce42dcebf6a"
   },
   "outputs": [],
   "source": [
    "# ---- Create a scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:, [\"Oxy_Balance\", 'num_type']], color=shap_values[:, 'q_per_g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09731e7-786d-4dee-ac68-45e98e15f32f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "b09731e7-786d-4dee-ac68-45e98e15f32f",
    "outputId": "66840d10-b023-430b-d232-eac3f65ba47b"
   },
   "outputs": [],
   "source": [
    "# ----Summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f6595-dca0-4d18-a8b6-a31ed8f578d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e42f6595-dca0-4d18-a8b6-a31ed8f578d1",
    "outputId": "06d6fdb0-d796-4626-809b-f027eb3a46b3"
   },
   "outputs": [],
   "source": [
    "# ---- Mean absolute value of the SHAP values and absolute values for each feature\n",
    "shap.plots.bar(shap_values)\n",
    "shap.plots.beeswarm(shap_values.abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cQBqEMXwz31G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "cQBqEMXwz31G",
    "outputId": "8fc9efbb-661c-4d6e-f588-274e99d5495e"
   },
   "outputs": [],
   "source": [
    "# ---- Mean absolute value of the SHAP values for each group\n",
    "group = [\"NNOO\" if shap_values[i, \"num_type\"].data == 0 else \"CN0O\" if shap_values[i, \"num_type\"].data == 1 else 'NOOO'\n",
    "         for i in range(shap_values.shape[0])]\n",
    "shap.plots.bar(shap_values.cohorts(group).abs.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742ebb1-22f2-4b29-a396-ddcc54698ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Shapley values through KernelExplainer\n",
    "# KernelExplainer estimates Shapley values by sampling subsets and comparing predictions with and without each feature (assumes independence)\n",
    "background_data = shap.sample(X_train, 3000, random_state=111166)  # 3000 is the number of subsets\n",
    "my_model = lambda x: my_best_rf_model.predict(pd.DataFrame(x, columns=list(X_train.columns)))\n",
    "ker_expl = shap.KernelExplainer(my_model, background_data, link='identity')\n",
    "shap_vals_ker = ker_expl(X_test.sample(len(X_test), replace=False, random_state=111166))\n",
    "\n",
    "shap.plots.bar(shap_vals_ker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L4astc248cxv",
   "metadata": {
    "id": "L4astc248cxv"
   },
   "outputs": [],
   "source": [
    "# ----Nw we are going to introduce the correlation between features\n",
    "# Get the distance_correlations between features\n",
    "clust = shap.utils.hclust(X_train, metric=distance_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1863fd3-15e6-4a06-be1a-fa5d6edbb458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----Accounting for feature interactions - correlations\n",
    "# Calculate Shapley values for feature coalitions, then distributing within each coalition\n",
    "# The PartitionExplainer creates a binary-hierarchal clustering of features and then caculates the feature attribution with the marginals respecting this binary partition tree\n",
    "masker = shap.maskers.Partition(X_train, clustering=clust)\n",
    "part_expl = shap.PartitionExplainer(my_model, masker)  # Specify feature coalitions based on their interactions\n",
    "shap_vals_part = part_expl(X_test.sample(len(X_test.values), random_state=111166))\n",
    "shap.plots.bar(shap_vals_part, clustering_cutoff=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010585e9-5d09-495d-82de-7f4c91abc642",
   "metadata": {
    "id": "010585e9-5d09-495d-82de-7f4c91abc642"
   },
   "source": [
    "# Visualizing graphs with the graphviz library\n",
    "1-Download an install graphviz form: https://graphviz.org/download/\n",
    "2- Run in the EDA environment: conda install graphviz python-graphviz pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5effc6-0810-439a-963d-c32713a68f48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "fc5effc6-0810-439a-963d-c32713a68f48",
    "outputId": "845511e0-a47f-4037-adf7-5ccb5b14aa58"
   },
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Choose some tree (the 0 tree in this example)\n",
    "choose_tree = 0\n",
    "estimator_to_plot = my_best_rf_model.estimators_[choose_tree]\n",
    "# Create the graph\n",
    "dot_data = export_graphviz(estimator_to_plot,\n",
    "                           out_file=None,\n",
    "                           feature_names=X.columns,\n",
    "                           filled=True,\n",
    "                           rounded=True,\n",
    "                           special_characters=True,\n",
    "                           impurity=True,\n",
    "                           max_depth=4)\n",
    "graph = graphviz.Source(dot_data)\n",
    "# Display the graph\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ccc51-28e0-43eb-8f93-7d7f737bd927",
   "metadata": {
    "id": "6b2ccc51-28e0-43eb-8f93-7d7f737bd927"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
